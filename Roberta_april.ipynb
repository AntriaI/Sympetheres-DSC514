{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v56NdKSuEX2H"
      },
      "source": [
        "On this notebook , we will attempt a preprocessing step before using the RoBERTa model since it has a max input length of 512 and our reviews are much longer. The longest sequence we have is around 1500 so we will break each review into 3 parts which we will be able to trace back to the original review using IDs and then aggregate."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3GF2PVcU3qX",
        "outputId": "03979b34-5ec3-4734-e38c-836a61b9b5eb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Apr  7 13:18:13 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA L4                      Off |   00000000:00:03.0 Off |                    0 |\n",
            "| N/A   55C    P8             13W /   72W |       0MiB /  23034MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GRaQsuNU9t3",
        "outputId": "e1642dcc-e6ed-4e84-bc39-00b6dbb9ede8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 56.9 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QB92xkEkFYjG"
      },
      "outputs": [],
      "source": [
        "!pip install datasets\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "g72_3HblCa4Z"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset, DatasetDict\n",
        "import torch\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "from transformers import RobertaTokenizer, RobertaConfig, RobertaForSequenceClassification, RobertaTokenizerFast, Trainer, TrainingArguments, EarlyStoppingCallback\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    print(\"No GPU detected, using CPU.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdoh_Vq6VNmU",
        "outputId": "c402e4bf-235e-4284-97b8-6b2b9dc1d837"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using GPU: NVIDIA L4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmx19uygFxnL",
        "outputId": "c660799b-f3be-455a-f5d9-fa8f859a3cc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive', force_remount = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        },
        "id": "P1L6zEQ5FUNN",
        "outputId": "fb9f224e-f548-48b2-eee8-3e471bb32d72"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    movie_id                                       plot_summary  duration  \\\n",
              "0  tt0015864  A lone prospector ventures into Alaska looking...  1h 35min   \n",
              "1  tt0015864  A lone prospector ventures into Alaska looking...  1h 35min   \n",
              "2  tt0015864  A lone prospector ventures into Alaska looking...  1h 35min   \n",
              "3  tt0015864  A lone prospector ventures into Alaska looking...  1h 35min   \n",
              "4  tt0017136  Sometime in the future, the city of Metropolis...  2h 33min   \n",
              "\n",
              "                              genre  rating_x release_date  \\\n",
              "0  ['Adventure', 'Comedy', 'Drama']       8.2         1925   \n",
              "1  ['Adventure', 'Comedy', 'Drama']       8.2         1925   \n",
              "2  ['Adventure', 'Comedy', 'Drama']       8.2         1925   \n",
              "3  ['Adventure', 'Comedy', 'Drama']       8.2         1925   \n",
              "4               ['Drama', 'Sci-Fi']       8.3   1927-03-13   \n",
              "\n",
              "                                       plot_synopsis      review_date  \\\n",
              "0  It is in the middle of the Gold Rush. A Lone P...  1 February 2006   \n",
              "1  It is in the middle of the Gold Rush. A Lone P...   11 August 2005   \n",
              "2  It is in the middle of the Gold Rush. A Lone P...     22 June 2000   \n",
              "3  It is in the middle of the Gold Rush. A Lone P...     9 March 2009   \n",
              "4  The film is set in the year 2026, in the extra...     7 March 2015   \n",
              "\n",
              "      user_id  is_spoiler                                        review_text  \\\n",
              "0   ur5945598        True  Oh where can I start on why alleged comedians ...   \n",
              "1   ur5805910        True  We follow \"the little fellow\" (Chaplin), in hi...   \n",
              "2   ur0773000       False  I recently saw this movie with a live orchestr...   \n",
              "3   ur0361658       False  The Gold Rush (1925) was a big undertaking for...   \n",
              "4  ur13977076        True  This sci-fi classic is set in a future where t...   \n",
              "\n",
              "   rating_y                                     review_summary  \\\n",
              "0        10                        Chaplin strikes comic gold!   \n",
              "1        10          Chaplin's delightful bonhomie & innocence   \n",
              "2         9  As fresh, funny, and moving as the day it was ...   \n",
              "3        10       The Cinema of Charles Chaplin: The Gold Rush   \n",
              "4        10                          A science fiction classic   \n",
              "\n",
              "                                        whole_review  \n",
              "0  Oh where can I start on why alleged comedians ...  \n",
              "1  We follow \"the little fellow\" (Chaplin), in hi...  \n",
              "2  I recently saw this movie with a live orchestr...  \n",
              "3  The Gold Rush (1925) was a big undertaking for...  \n",
              "4  This sci-fi classic is set in a future where t...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a2ac2130-8435-4166-ae57-a194dfae3c31\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movie_id</th>\n",
              "      <th>plot_summary</th>\n",
              "      <th>duration</th>\n",
              "      <th>genre</th>\n",
              "      <th>rating_x</th>\n",
              "      <th>release_date</th>\n",
              "      <th>plot_synopsis</th>\n",
              "      <th>review_date</th>\n",
              "      <th>user_id</th>\n",
              "      <th>is_spoiler</th>\n",
              "      <th>review_text</th>\n",
              "      <th>rating_y</th>\n",
              "      <th>review_summary</th>\n",
              "      <th>whole_review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tt0015864</td>\n",
              "      <td>A lone prospector ventures into Alaska looking...</td>\n",
              "      <td>1h 35min</td>\n",
              "      <td>['Adventure', 'Comedy', 'Drama']</td>\n",
              "      <td>8.2</td>\n",
              "      <td>1925</td>\n",
              "      <td>It is in the middle of the Gold Rush. A Lone P...</td>\n",
              "      <td>1 February 2006</td>\n",
              "      <td>ur5945598</td>\n",
              "      <td>True</td>\n",
              "      <td>Oh where can I start on why alleged comedians ...</td>\n",
              "      <td>10</td>\n",
              "      <td>Chaplin strikes comic gold!</td>\n",
              "      <td>Oh where can I start on why alleged comedians ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tt0015864</td>\n",
              "      <td>A lone prospector ventures into Alaska looking...</td>\n",
              "      <td>1h 35min</td>\n",
              "      <td>['Adventure', 'Comedy', 'Drama']</td>\n",
              "      <td>8.2</td>\n",
              "      <td>1925</td>\n",
              "      <td>It is in the middle of the Gold Rush. A Lone P...</td>\n",
              "      <td>11 August 2005</td>\n",
              "      <td>ur5805910</td>\n",
              "      <td>True</td>\n",
              "      <td>We follow \"the little fellow\" (Chaplin), in hi...</td>\n",
              "      <td>10</td>\n",
              "      <td>Chaplin's delightful bonhomie &amp; innocence</td>\n",
              "      <td>We follow \"the little fellow\" (Chaplin), in hi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tt0015864</td>\n",
              "      <td>A lone prospector ventures into Alaska looking...</td>\n",
              "      <td>1h 35min</td>\n",
              "      <td>['Adventure', 'Comedy', 'Drama']</td>\n",
              "      <td>8.2</td>\n",
              "      <td>1925</td>\n",
              "      <td>It is in the middle of the Gold Rush. A Lone P...</td>\n",
              "      <td>22 June 2000</td>\n",
              "      <td>ur0773000</td>\n",
              "      <td>False</td>\n",
              "      <td>I recently saw this movie with a live orchestr...</td>\n",
              "      <td>9</td>\n",
              "      <td>As fresh, funny, and moving as the day it was ...</td>\n",
              "      <td>I recently saw this movie with a live orchestr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tt0015864</td>\n",
              "      <td>A lone prospector ventures into Alaska looking...</td>\n",
              "      <td>1h 35min</td>\n",
              "      <td>['Adventure', 'Comedy', 'Drama']</td>\n",
              "      <td>8.2</td>\n",
              "      <td>1925</td>\n",
              "      <td>It is in the middle of the Gold Rush. A Lone P...</td>\n",
              "      <td>9 March 2009</td>\n",
              "      <td>ur0361658</td>\n",
              "      <td>False</td>\n",
              "      <td>The Gold Rush (1925) was a big undertaking for...</td>\n",
              "      <td>10</td>\n",
              "      <td>The Cinema of Charles Chaplin: The Gold Rush</td>\n",
              "      <td>The Gold Rush (1925) was a big undertaking for...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>tt0017136</td>\n",
              "      <td>Sometime in the future, the city of Metropolis...</td>\n",
              "      <td>2h 33min</td>\n",
              "      <td>['Drama', 'Sci-Fi']</td>\n",
              "      <td>8.3</td>\n",
              "      <td>1927-03-13</td>\n",
              "      <td>The film is set in the year 2026, in the extra...</td>\n",
              "      <td>7 March 2015</td>\n",
              "      <td>ur13977076</td>\n",
              "      <td>True</td>\n",
              "      <td>This sci-fi classic is set in a future where t...</td>\n",
              "      <td>10</td>\n",
              "      <td>A science fiction classic</td>\n",
              "      <td>This sci-fi classic is set in a future where t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a2ac2130-8435-4166-ae57-a194dfae3c31')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a2ac2130-8435-4166-ae57-a194dfae3c31 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a2ac2130-8435-4166-ae57-a194dfae3c31');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1661ad7e-36e7-4029-b3a4-5f2e6c1f35ba\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1661ad7e-36e7-4029-b3a4-5f2e6c1f35ba')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1661ad7e-36e7-4029-b3a4-5f2e6c1f35ba button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5335,\n  \"fields\": [\n    {\n      \"column\": \"movie_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1339,\n        \"samples\": [\n          \"tt0119396\",\n          \"tt0482571\",\n          \"tt0117665\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"plot_summary\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1339,\n        \"samples\": [\n          \"The middle-aged stewardess Jackie Brown smuggles money from Mexico to Los Angeles for the arms dealer Ordell Robbie. When she gets caught by the agents Ray Nicolet and Mark Dargus with ten thousand dollars and cocaine in her purse, they propose a deal to her to help them to arrest Ordell in exchange of her freedom. Meanwhile Ordell asks the 56-year-old Max Cherry, who runs a bail bond business, to release Jackie Brown with the intention of eliminating her. Jackie suspects of Ordell's intention and plots a complicated confidence game with Max to steal half a million dollars from Ordell.                Written by\\r\\nClaudio Carvalho, Rio de Janeiro, Brazil\",\n          \"In the end of the Nineteenth Century, in London, Robert Angier, his beloved wife Julia McCullough and Alfred Borden are friends and assistants of a magician. When Julia accidentally dies during a performance, Robert blames Alfred for her death and they become enemies. Both become famous and rival magicians, sabotaging the performance of the other on the stage. When Alfred performs a successful trick, Robert becomes obsessed trying to disclose the secret of his competitor with tragic consequences.                Written by\\r\\nClaudio Carvalho, Rio de Janeiro, Brazil\",\n          \"As children, Lorenzo Carcaterra - Shakes to his friends - Michael Sullivan, Tommy Marcano, and John Reilly were inseparable. They grew up in Hell's Kitchen, a far from perfect neighborhood, one filled as Shakes says with scams and shake downs, but one where the rules were known by its residents. The one adult who they admired was Father Bobby Carelli, who understood them as kids more than most adults and more than he himself would like to admit. In 1967, their lives would change forever when a typical teenage prank went wrong which led to the four of them being sentenced to various terms at Wilkinson Home for Boys, a reformatory. There, they were physically, emotionally and sexually abused primarily by Sean Nokes, the head guard of their cell block, and fellow guards Ralph Ferguson, Henry Addison, and Adam Styler, although there were other caring figures of authority at the home including other guards. Their time at the home affected the four, not all who were able to emerge from the ...                Written by\\r\\nHuggo\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"duration\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 129,\n        \"samples\": [\n          \"2h 27min\",\n          \"2h 52min\",\n          \"1h 33min\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"genre\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 218,\n        \"samples\": [\n          \"['Horror']\",\n          \"['Comedy', 'Music']\",\n          \"['Action', 'Adventure', 'Horror']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rating_x\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.903827140550643,\n        \"min\": 2.4,\n        \"max\": 9.3,\n        \"num_unique_values\": 55,\n        \"samples\": [\n          6.8,\n          8.5,\n          7.7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"release_date\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1063,\n        \"samples\": [\n          \"1954-06-22\",\n          \"1999-03-05\",\n          \"2003-02-21\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"plot_synopsis\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1339,\n        \"samples\": [\n          \"Los Angeles,1995. Jackie Brown (Pam Grier) is a flight attendant for a small Mexican airline called Cabalas Airlines which flies only from L.A. to Cabo San Lucas, the latest step down for her career. Despite the low pay, the job enables her to smuggle money from Mexico into the United States for Ordell Robbie (Samuel L. Jackson), a gun runner under the close watch of the ATF.One day, Ordell learns that another of his workers, Beaumont Livingston (Chris Tucker), has been arrested. Fearing that Livingston will become an informant in order to avoid jail time, Ordell arranges for his $10,000 bail with bail bondsman Max Cherry (Robert Forster). That same evening, Ordell promptly leads Livingston to his death by tricking him into getting into the trunk of a stolen car where Ordell shoots him to death.Acting on information Livingston had indeed shared after his arrest, ATF agent Ray Nicolette (Michael Keaton) and LAPD detective Mark Dargus (Michael Bowen) intercept Jackie as she arrives in the United States with Ordell's cash and some cocaine that Brown was unaware was stashed along with the $30,000 cash. She initially refuses to cooperate with Nicolette and Dargus, so Jackie is sent to jail on possession of drugs with intent to sell. Sensing that Jackie may be just as likely to inform as Livingston had been, Ordell goes back to Max Cherry and sets out to arrange Jackie's bail so he can plot to kill her too once she is released.That evening, Max Cherry arrives at the jail to pick Jackie up and, only partly masking his physical attraction, offers to buy her a drink and help determine her legal options. Over drinks at a local bar, Jackie senses an attraction that Max has on her, but reminds him that she is not interested. After dropping her off at her apartment, Jackie steals Max's gun that he kept hidden in his glove compartment.Later that night, Ordell arrives at Jackie's apartment apparently intending to murder her. Jackie pulls out the gun she stole/borrowed from Cherry and she holds him at gunpoint. Jackie barters a deal with Ordell whereby she will pretend to help the authorities while still managing to smuggle $500,000 of Ordell's money out of Mexico, enough to allow him to retire and flee to some distant country and retire. To carry out this plan, Ordell employs a woman he lives with, \\\"my little blond surfer girl\\\"; a drug-addicted beach bunny named Melanie Ralston (Bridget Fonda), plus his friend, Louis Gara (Robert De Niro), a former cellmate whom has shacked up with him. Ordell also uses a na\\u00efve Southern girl, Sheronda (Lisa Gay Hamilton) as his co-conspirator to give him an alibi for when the transaction will take place.The following day, Jackie meets at LAPD headquarters with Agent Nicolette and Detective Dargus to arrange a sting to catch Ordell. But Nicollette and Dargus are both unaware that Jackie and Ordell plan to double cross them by diverting the actual money before the authorities make an arrest. Unbeknownst to the others, Jackie plans to deceive them both with the help of Cherry in order to keep the $500,000 for herself. However, in another twist, Melanie tries to convince Louis to steal the $500,000 that Jackie will hand over to them and flee the country with the money for themselves. Though Louis agrees, he does not trust Melanie for she might take all the money for herself out of greed, while Melanie clearly suspects likewise about Louis.After a dry run, during which Nicolette could observe the operation, the stage is set for the actual event. Told from three different viewpoints (a nod to 1950s film noirs) the exchange takes place in a large shopping mall near Los Angeles (the Del Amo Fashion Center).Jackie's version: At the mall, Jackie enters the Billingsley department store where she buys a new suit and enters a dressing room. Her real intention is to swap bags there with Melanie and Louis, supposedly passing off the $500,000 under Nicolette's nose. Instead, she gives Melanie only $50,000 and leaves the rest behind in the dressing room for Max Cherry to pick up. Jackie then feigns despair as she leaves the department store and into the mall where she calls Nicolette and Dargus out from hiding and claims Melanie took all the money and ran.Louis and Melanie's version: Louis meets Melanie at Ordell's beachfront house while Ordell goes to a local bar-restaruant, called the Cockatoo Bar with Sheronda to have an alibi to his whereabouts for the day. Melanie gets on Louis case from the start when they are late for the rendevouz because Louis finds Melanie wasting time by getting high in the bathroom with smoking a basepipe. During the drive to the mall, the stoned Melanie annoys Louis more by playing loud rock music over the van radio. During the switch, Melanie enters the dressing room at Billingsley's with a brown bag of beach towels to make the switch while Louis waits outside, where he catches a glimpse of Max Cherry standing nearby. Melanie exits the dressing room with the other brown bag containing part of the cash. In the parking lot, Melanie gets on Louis' nerves more and more, which finally leads him to shoot and kill her while making their escape after she mouths off one too many times.Max Cherry's version: Max arrives at the mall alone and at the Billingsley's department store where he eyes Jackie from a distance and tries to hide when Louis and Melanie walk by to make the switch, but Louis catches a glimpse of him as they walk by. After Louis and Melanie leave the store, Jackie, pretending to be in dispair, pays for her new business suit and leaves the store. When Jackie leaves, Max approaches the sales clerk and claims that his wife left a bag in the dressing rooms for him, which Max picks up the bag containing the $500,000 cash and quietly leaves the store where he drives to his office to stash the cash before driving home.Across town, Louis then picks up Ordell from the Cockatoo Bar where he soon discovers that Louis has only $40,000 in the bag (Melanie having kept $10,000 for herself after being tricked into doing so by Jackie, which is apparently left on her dead person). Then Ordell realizes that it was Jackie who took his money, and in anger, a suspicious Ordell kills his friend Louis. He is also concerned about the involvement of Max Cherry, having been told by Louis that he spotted Max in the store before the pickup.At police headquarters, Agent Nicollette is angry with Jackie for what transpired during the pickup (Jackie apparently told him that the money that she was carrying was only $50,000, not the entire $500,000 from Ordell's secret account in Mexico). Nicollette tells Jackie about finding Melanie in the mall parking lot with $10,000 on her, and about finding Louis a short distance away in his van. Nicollette tells Jackie that she has only one more chance to cooperate with them to catch Ordell and find the rest of the money.That evening, Ordell goes to the Cockatoo Bar where Max is and pulls a gun on him and demands that he help him find Jackie who has his money. Lured back to Max's office, where Jackie is said to be frightened and waiting to hand over his money, Ordell arrives armed and dangerous. Jackie suddenly yells out that Ordell has a gun and he is shot by Nicolette, who was hidden in another room.Three days later. In the clear with the law and in possession of the $500,000, Jackie decides to leave town for a while, and she invites Max to run off with her. Max is tempted, clearly in love with her as they kiss, but he declines to go with Jackie for reasons that are left unclear.Note: There are a number of hints during the movie given by Cherry in his dialogue with Jackie about why he makes the choices he makes and does not act out of greed. Some include Max's wanting to get out of the bail bond business and find something else to do to being too old to start a new adventure in life (\\\"I'm just tired in general....\\\"), but his reasons for turning down an offer to run off with a woman he is obviously in love with remains intentionally ambiguous at the film's closing.\",\n          \"The Prestige begins with shots of several dozen top hats inexplicably strewn about in a forest.Cutter (Michael Caine), in voiceover, explains the three parts of a magic trick while performing a disappearing bird trick for a little girl. Part one is the pledge, where the magician shows you something ordinary, like a bird. Part two is the turn, where he does something extraordinary, like make the bird disappear. But this isn't enough. There always has to be a third act, the prestige, where you have a twist, and bring the bird back. Only then will the audience applaud.Robert Angier (Hugh Jackman), stage name \\\"the Great Danton,\\\" attempts a transporting trick that involves walking under a giant electrical machine with a Tesla coil and then disappearing through a trapdoor. Except that he falls straight into a giant tank of water that has been placed under the stage, and is automatically locked inside. A man in the audience, who we shortly learn is fellow magician Alfred Borden (Christian Bale), stage name \\\"the Professor,\\\" forces his way beneath the stage in time to see Angier drown.After this introduction, we follow three timelines at once. In the present day (19th century England), Borden is on trial for murdering Angier, who we learn was his greatest rival. Cutter is revealed to be Angier's engineer, the man who builds the machinery for his tricks, and the little girl is Borden's daughter Jess (Samantha Mahurin).Cutter confides to the judge in a private meeting that the machine Angier was using wasn't built by him, but by \\\"a wizard,\\\" and it legitimately did what it appeared to do.The trial does not go well for Borden, and he faces execution. Later, in jail, Borden is approached by the solicitor for a collector, Lord Caldlow, who is interested in buying his secrets, particularly the secret of Borden's famous \\\"Transported Man\\\" trick. The same collector has also bought all of Angier's equipment and props. When Borden refuses, the solicitor threatens that Jess is in danger of being declared an indigent orphan and sent to the workhouse unless his patron intervenes. As an incentive, he gives Borden Angier's diary, which documents the time he spent in Colorado trying to learn Bordon's secret.Borden's reading of the diary in prison frames the second part of the narrative, which is from Angier's point of view. Angier is on a train in the Rocky Mountains, headed to Colorado Springs, Colorado, on his way to see the notorious scientist Nikola Tesla (David Bowie). Disembarking at the train station in town, Angier is taken by coach to the inn, where he gets an unusually warm welcome from the hotel staff. The manager tells Angier that he's their first guest of the winter. Angier asks if a ride can be arranged to take him up to Pike's Peak the next day, but is told that the peak is closed for experimentation.The next day, Angier is dropped off on a dirt track in the woods, at the farthest point the carriage can take him. He makes his way up to the fence surrounding a clearing. He is immediately thrown back as the fence is electrified. Tesla's assistant Alley (Andy Serkis) comes out of the gatehouse, thinking at first that Angier is another intruder, then recognizes him, saying he's seen Angier's London show. Angier says he's come to ask Tesla to build him a machine like one that he believes Tesla built for Borden -- the machine that allows Borden to do the \\\"Transported Man\\\" trick. Alley says he can't help Angier, and Angier heads back to the hotel, disappointed. Alley takes satisfaction when Angier, back turned to him, correctly guesses that Alley is holding a gold watch in his hand.Angier sits down in his room and begins decoding a diary he stole from Borden, which is encrypted with a particular five-letter-word passcode (important later).Borden's diary frames the third thread of the narrative, which goes back to the very beginning.Angier and Borden are partners, up-and-comers working for an elderly magician named Milton (Ricky Jay). Milton also employs Cutter and Angier's wife Julia (Piper Perabo). Their best trick is an underwater escape act. In this act, Angier and Borden are planted in the audience and called up to the stage to tie Julia's wrists and ankles before she is hoisted up on a pulley and dropped into a water tank. A curtain descends on the tank, and Julia slips the knot around her wrists and escapes using a trick lock on the tank. As a safety precaution, Cutter is positioned stage right, behind the curtains, with a stopwatch and an axe.Angier and Borden are on friendly terms, though Angier is somewhat concerned that Borden might be using a knot that is more difficult for Julia to slip. We learn that Angier is using an alias so he won't embarrass his prominent family with his theatrical pursuits, while Borden and his engineer Fallon come from a rougher background. Borden is much more ambitious than Angier, isn't afraid to do dirtier tricks, and wishes Milton would try more dangerous tricks, like a bullet catch. Borden claims to have created a trick that will be his masterpiece.One day, Cutter sends Angier and Borden to watch a Chinese magician, Chung Ling Soo (Chao Li Chi), and figure out exactly how the man makes a heavy goldfish bowl (filled with water and goldfish) appear from under a cloth. Borden immediately deduces that the old magician is really putting up a front: he's holding the bowl between his legs under his skirt, hiding the strength required to accomplish the trick by always appearing frail in public. Borden admires the way the Chinese magician goes to such an extreme that he \\\"lives\\\" his performance at home. Angier is surprised, since when he tries holding an empty goldfish bowl at home, he has a hard time carrying it.As his prize for working out the fishbowl trick, Borden gets a few minutes onstage assisting Milton during a performance, where he performs a trick where a bird and cage disappear simultaneously, and then the bird reappears. A boy in the audience becomes upset when he realizes the bird in the cage isn't the same as the one that reappears. Borden tries to help the boy's aunt, a woman named Sarah (Rebecca Hall), to console him. After the show, we discover that the bird in the cage has to die to achieve the illusion, as Borden is seen tossing the original bird in the trash. Borden and Sarah strike up an acquaintance and become romantically involved.Disaster strikes during the next performance of the underwater escape. Borden ties, stops, and then reties the knot around Julia's hands as they prepare to put her on the hoist. She can't manage to slip the knot underwater, and Cutter isn't able to break the glass of the tank in time to save her. Julia dies onstage, leaving Angier devastated and Milton ruined. During the funeral, Angier confronts Borden, asking which knot he tied. His answer is that he \\\"doesn't know,\\\" which Angier cannot accept. This is the beginning of their bitter rivalry.Borden and Angier both strike out on their own, but there are obvious tensions. Borden marries Sarah and starts doing his own act, the climax of which is a bullet-catching trick. The secret, as Borden explains to his pregnant wife, is that the bullet is palmed, so that it's already in the magician's hand when the gun is fired. All that comes out of the pistol is gunpowder. But magicians have died during the trick because of audience members sticking buttons or their own bullets into the guns.Borden is next seen performing for a very rowdy audience. After whipping out the gun to silence the audience, he asks for volunteers, then hands the gun to a man who is actually a disguised Angier. Angier, knowing the trick, deliberately puts his own bullet into the gun, and confronts Borden again about the knot he tied. When Borden's answer is still \\\"I don't know,\\\" Angier shoots him, blowing the ends of two fingers off his left hand and jeopardizing Borden's career. Sarah encourages him to quit magic. She isn't happy that Borden keeps secrets from her as part of his trade. Their marriage is an uneven one, and she claims that when he says that he loves her, she can tell on some days he doesn't mean it. Borden admits this is true and they make a sad little game of it: some days he loves her, some days he loves the magic.One day at a bar, Angier is approached by Cutter, whom no one will hire because of his association with Milton. They start their own act, with Angier performing as \\\"the Great Danton\\\" (a name suggested by his late wife and rejected at the time for being \\\"too French\\\"). His lovely assistant is a blonde bombshell named Olivia Wenscombe (Scarlett Johansson). Because Angier doesn't want to get dirty, Cutter comes up with a new version of the \\\"disappearing-bird-in-the-cage\\\" trick where members of the audience keep their hands on the cage as it disappears. The trick involves mechanical gadgetry that Angier wears under his suit to fold away and retract the cage. Best of all, the bird is unharmed.Angier debuts the trick at his show. The audience is negative at first, complaining that they've seen the trick numerous times, but Angier says he'll make it a bit harder. He asks for two volunteers to come up from the audience. Two are selected: an elderly woman and a man who is actually a disguised Borden. Although Angier recognizes Borden the moment he puts his hand on the cage, he is unable to stop Borden from jamming the machinery. The cage malfunctions, causing the bird to be killed onstage and the other volunteer's hand to be caught. The theater owner cancels Angier's booking and Angier's reputation is left in tatters.Cutter sends Angier to a science lecture to get some new ideas. Nicola Tesla is preparing to demonstrate several huge, fantastic Tesla coils, generating immense electric charges that seem to fill the room. Because of the perceived danger, the demonstration is canceled by the authorities. But Angier spots Borden in the crowd and follows him, learning about Sarah and their new baby, Jessica. Fed by jealousy of Borden's happiness, which Angier feels should have been his, Angier's obsession over the rivalry grows.Intercut with this storyline are Angier's attempts to meet with Tesla and commission his own transporter machine. Tesla has supplied all of Colorado Springs with electrical service in exchange for being allowed full use of the generators at night (when the residents are sleeping) to conduct experiments. He's even rigged up his own electric fence. When Tesla finally agrees to build the machine for Angier, he warns that it will take a great deal of time and money.In Borden's diary, we learn that both magicians start performing again. Borden, as \\\"the Professor,\\\" has a dramatic new trick called the Transported Man that has been getting him attention. Angier and Olivia, who is falling in love with her magician, watch it repeatedly and are unable to tell how he does it. The trick appears amazingly simple: Borden gets into a cabinet on stage right and gets out of another cabinet on stage left. Cutter insists that he must be using a double, but Olivia insists that she can see the bandaged stumps on his left hand both when Borden disappears and when he reappears, even though Borden wears padded gloves to hide his short fingers.Angier and Cutter copy the trick and add the bit of showmanship and flair that Borden's version is missing. In his version, Angier throws his hat across the stage and walks through a door on one side of the stage, secretly drops through a trapdoor hidden behind the door frame onto a padded cushion, while a double simultaneously is hoisted out of another trapdoor behind the door on the other side of the stage to catch the hat. They hire an out-of-work actor named Gerald Root (also played by Hugh Jackman) to be Angier's double. He's a drunk and a lout, but he can perform.Their act, dubbed \\\"the New Transported Man,\\\" is an amazing success. But there's one small drawback: Angier has to be the one who sells the buildup of the trick, so he's always under the stage during the prestige and misses out on the audience reaction. Root is getting all the glory, even if Cutter makes sure that he keeps a low profile so the secret doesn't get out. Even worse, Angier still doesn't know how Borden does his version of the trick.Angier decides to send Olivia to work for Borden and spy on him to get the secret. Olivia, who is in love with him, doesn't like the idea, but does as Angier asks and becomes Borden's assistant. To gain his trust, she tells Borden how Angier's trick is done and offers to help him improve on his own act.Meanwhile, a big problem develops -- with Root, of course. Root realizes that he can control Angier because he's necessary for Angier's biggest trick, and demands money. It turns out that Borden has been influencing him, and Cutter thinks Olivia may have betrayed them. Borden's version of the \\\"Transported Man\\\" has improved, and now includes one of Tesla's electricity-generating machines. Cutter gets Angier to agree to phase out the trick.Root's performances get more intentionally sloppy, and one night he simply isn't there at all. When Angier goes through the trapdoor, the cushion to break his fall has been removed, and he breaks his leg. He watches Borden pop out of Root's trapdoor and proceed to humiliate him, suspending a tied-up Root from the ceiling with an advertisement for Borden's own act, before running out of the theater to his own show.Angier confronts Olivia, who insists that Borden's trick is accomplished using a double, because she's seen makeup and wigs lying around. He deduces that such items are planted by Borden as misdirection for her. When he questions her loyalty, she produces Borden's encrypted diary as proof that she didn't betray him. However, the five-letter-word to decrypt the diary is still necessary. Angier and Cutter kidnap Fallon, Borden's engineer, and nail him in a box to hold for ransom.When Borden comes to the meeting place in a cemetery to get Fallon back, Angier demands to know the secret of Borden's \\\"Transported Man\\\" in exchange. Borden writes down one word, \\\"Tesla,\\\" which will decode the diary, and suggests that he's teleporting using a machine Tesla built. Borden is then told that Fallon has been buried alive, and Angier asks him how fast he can dig.Angier leaves for America to track down Tesla, for the second section of the narrative, while Cutter stays behind. He was shot by Fallon in the shoulder while nailing the box up, and doesn't want to pursue the secret of the trick any further. Tesla refuses to meet with Angier, and the latter learns that Tesla has run out of funding and is being hounded by his rival, Thomas Edison. Angier assures Tesla that money is no object and Tesla tells him in turn that the machine is already being built.Borden's private life starts falling apart. He's having an affair with Olivia, and his wife is drinking because of their deteriorating marriage. At one point, he instructs Fallon to deal with his family while going to see Olivia. He appears to genuinely care for both women.Sarah eventually hangs herself in Borden's workroom, after trying to confront her husband about one of his secrets.In Colorado, Tesla and Alley have been unsuccessfully testing the machine they built for Angier. They've zapped his top hat time after time with an impressive electrical apparatus, but the hat won't move an inch.Angier comes to the end of Borden's diary and realizes that Olivia actually did betray him. She was in love with Angier, but since he used her as a spy without concern for her feelings, she knew she didn't have a future with him. She gave Angier the diary to prove her loyalty to Borden, who wrote it for Angier. The last entry in the diary tells him that \\\"Tesla\\\" was the keyword to decrypt the writing, which is true, but it's not the secret to the trick at all. Tesla never built a teleportation machine for Borden, and Angier has been sent on a wild goose chase.He goes back to Tesla's lab several times, where the scientist insists that he is capable of building a teleporter, but he never built one for Borden. He tests the machine again, this time using Alley's precious black cat. Alley warns Tesla not to harm the cat. Alley, using the cat's beautiful collar, chains the cat to the spot for the experiment, as Tesla thinks it may be a matter of needing something living. The cat does not like the procedure and hisses, but is completely unharmed. However, the cat doesn't move at all, so Angier leaves in disgust. Then the cat is freed and runs out the front door.As Angier walks back through the woods, we revisit the first shot of the movie: a heap of top hats on the forest floor. And this time, there are two identical (proved by the collar) black cats among them. The machine has been working all along, but instead of moving an object from one place to the other, it creates a duplicate at the destination. Tesla and Alley are amazed, moving from hat to hat and measuring them with calipers. When Angier leaves, Tesla tells him to take his hat. He asks which hat is his and Tesla, smiling for the first time, says \\\"They are all your hat.\\\"Tesla and Alley continue to refine the machine now that they know how it works. They have to leave suddenly in the middle of the night when their lab is burned down by Edison's goons. However, in the care of the hotel manager, Tesla leaves a large, trapezoidal wooden box for Angier, containing the components of the machine with instructions in a note. Tesla's note cautions Angier that using the machine is inviting Angier's doom and warns him to destroy the machine rather than use it.Angier takes the box back to England and reunites with Cutter. He's ready to perform again, but this time he's extremely secretive about his methods, hiring blind stage hands and not allowing Cutter backstage at any time. As he demonstrates to an influential promoter, he is zapped with electricity from the machine's Tesla coil, disappears from plain sight, and then reappears up in the balcony, appearing to traverse the distance instantaneously.The show is a hit and Borden is mystified. All he can tell is that Angier's trick involves a trapdoor, but he has no idea what's going on under the stage. Every night, he can see the blind stagehands removing a box from the theater.A few nights later, at another performance, Borden sneaks under the stage, as we saw in the prologue, and watches Angier fall through the trapdoor into the tank and drown. It's clear that Borden didn't have anything to do with it, and he actually tries to save his rival's life by attempting to break through the glass of the tank with a pipe. Cutter runs down under the stage and gets the wrong idea. Borden is arrested. Angier is confirmed dead with Cutter identifying the body.In his prison cell back in the present day, Borden comes to the end of Angier's diary, which gloats that Borden is being blamed for his death. Borden believes the diary must be a fake, until he's called out of his cell to say goodbye to Jess and meet the collector who wants to buy his secrets.The collector, Lord Caldlow, is Angier. Borden is dismayed that he would go so far and involve his child in their rivalry. Caldlow/Angier refuses to help clear his name, and won't even take the secret of Borden's \\\"Transported Man\\\" when bribed, telling him \\\"mine is better.\\\" Borden swears he'll get out and have his revenge, promising Jess he'll come for her.Cutter discovers Angier alive when he calls on Lord Caldlow to offer him the machine, hoping to convince him to destroy it. Cutter quickly realizes that Angier is remorseless about framing Borden. He says he's figured out the secret to Angier's version of \\\"the Transported Man\\\" and thinks he's gone too far.Borden has one last visitor: Fallon. Borden tells him what he's learned, gives him the rubber ball he sometimes uses for tricks, and tells Fallon to go \\\"live for both of us.\\\"Cutter brings the machine to Angier, and as he leaves, we see Fallon arrive to confront Angier. This is intercut with scenes of Borden being hanged. Borden dies just as Fallon shoots Angier. The camera pans up to reveal that \\\"Fallon\\\" has two missing fingers and Borden's face.Angier finally realizes that the secret of Borden's \\\"Transported Man\\\" was simple: Borden had a twin brother, and they were switching back and forth between the double roles of Borden and Fallon. One of them loved Sarah, and one of them loved Olivia. They both lived half of the same life, never telling anyone in order to maintain the illusion. In a flashback, it is shown that the unmutilated twin willingly let his brother amputate the ring and pinkie fingers on his left hand so that they could make the swaps without anyone telling the difference. Sarah, in a scene we've seen before, is puzzled and worried as to why the wound looks new and bruised again; Borden distracts her by slamming a fist down and saying they can't afford a doctor.Angier, who only ever cared about the glory of wowing an audience, went to far more terrible extremes. In his \\\"New Transported Man,\\\" he knowingly created a double of himself every time he used Tesla's machine, and he rigged the trapdoor to drown the one onstage. He never knew if he would be the prestige or the man in the box. The room where the machine is being kept is filled with water tanks, all of which hold a drowned double of Angier for every time he performed the trick. Several times, he mutters to himself a line we've heard before in a different context: \\\"No one cares about the man in the box.\\\"Angier falls and kicks over the lantern as he dies from his wound, and the resulting fire ensures the machine and all the evidence are destroyed.We loop back to the trick with the small birds in the opening scene (though this time, no birds are harmed) while Cutter reiterates the three parts of a magic trick. As Cutter has told Jess Borden, \\\"before the audience can clap, you have to make the disappeared man come back.\\\" On cue, her father appears to reclaim her. She runs into his arms, and Borden and Cutter exchange nods.\",\n          \"Told through the narration of a grown-up \\\"Shakes\\\", four young boys: Lorenzo \\\"Shakes\\\"(Joseph Perrino), Michael (Brad Renfro), Tommy (Jonathan Tucker), and John (Geoffrey Wigdor) are the best of friends growing up in Hell's Kitchen in New York City. Their family lives are hard, involving broken homes and spousal abuse, and the boys turn to street antics and volunteering as altar boys to escape. Father Bobby (Robert De Niro), an ex convict turned priest, watches out for them and tries to mold them into upstanding members of society. Despite their good hearts the boys get into all kinds of trouble, including sneaking into confessionals and pretending to be priests and playing pranks on nuns. Shakes becomes an errand boy and fast friends with a street kingpin named King Benny who runs all the illegal activity in Hell's Kitchen.One fateful day Michael suggests they knock off a hotdog vendor out of boredom. When Shakes runs off with a hotdog the vendor gives chase, leaving the stand unsupervised and allowing the three other boys to feast in his absence. Michael suggests that they leave the cart teetering on the edge of the subway entrance so when the vendor comes back he'll have to struggle to keep it from falling, giving them time to escape. In a tragic turn of events, the cart crashes down the stairs hitting and almost killing an elderly man.The boys are sentenced to a year in the Wilkinson Home for Boys. Because Shakes arrived at the scene of the cart crash later than the others (and because of the vouching of Father Bobby), he's only sentenced to 6 months. The boys hardly fit into the home which is filled with boys who have committed much more serious crimes and are subject to their ridicule and beatings. Worst of all is a guard named Sean Nokes (Kevin Bacon) who quickly turns the boys lives into a living hell. He begins by humiliating them along with three other guards, Henry Addison, Adam Styler and Ralph Ferguson (Jeffrey Donovan, Lennie Loftin and Terry Kinney respectively). Nokes embarrasses them in front of the other inmates by making them eat off the floor. The abuse escalates to beatings at night. He and the three other guards drag the four boys into the basement of the home where they repeatedly beat and rape them. It's suggested that this abuse becomes a nightly occurrence for the boys.The boys, no longer innocent and filled with shame, write to their parents to tell them not to visit; afraid they'll know what's been going on. Father Bobby refuses to stay away and urges Shakes to not let the home change him for the worse.The home holds a football game between the guards and inmates once a year for all the town to see. Michael convinces Rizzo, an intimidating black inmate to not let the guards win this year out of fear of the consequences but instead fight back as hard as possible. Rizzo agrees and the four boys and a few other inmates fight dirty and beat the guards in front of the whole town. Disgraced and angry, Nokes and the other guards throw the four boys into solitary confinement, starving them for two weeks straight. Shakes wakes up in the infirmary and is told by Michael that the guards beat Rizzo to death.As Shakes' release date nears, the four boys agree that once they get out of the home they won't breathe a word about what happened there to anyone and bury it as deep in their minds as possible.---------More than ten years later, two men walk into a pub and order a drink. Shakes' narration describes them as two of the most dangerous men in Hell's Kitchen. Both are members of the gang The West Side Boys. Both are murderers and drug users. The blonde man walks towards the bathroom and notices Nokes sitting by himself and eating dinner. He stares him down and Nokes reacts with annoyance. The blonde man tells him to enjoy his dinner and enters the bathroom. He returns to his dark-haired friend at the bar and tells him to look closely at Nokes. The dark-haired man recognizes him too and they both approach him. They sit down and introduce themselves as grown-up Tommy and John (Billy Crudup and Ron Eldard). Nokes says they were wimpy kids and he tried to make them tough. They point their guns at him. He tells them they're going to burn in hell. John says \\\"You first\\\", before they shoot him dead. Several people in the bar witness the shooting and hide their heads as Tommy and John walk out.Meanwhile, Shakes (Jason Patric), now a newspaper columnist, meets with Michael (Brad Pitt), now an assistant district attorney. Michael says he's going to take the Sean Nokes murder case as the prosecuting attorney. Shakes reacts with anger before Michael tells him he's going to take the case to lose. Not only that, he's planning on revealing the corrupt Wilkinson Home for what it really is. He asks Shakes to help him bring his plan to fruition. Michael hands Shakes years of research on the three other guards who had tortured them all those years ago.Shakes meets with Carol (Minnie Driver), a childhood friend of the boys and ex-girlfriend of Michael, and asks for her help finding files for the case since she has access as a social worker. She tells him that she's with John now and asks why he never asked her out. He said he never had the guts because she was Mikey's girl.Shakes enlists the help of King Benny who makes sure the fallen and disgraced drunk, Danny Snyder (Dustin Hoffman), is Tommy and John's defense lawyer, making it seem even less likely the two men will walk. Shakes meets with an internal affairs agent to give him information on Adam Styler, who has now become a cop, and his cocaine habit as well as his illegal trafficking activity. King Benny meets with drug kingpin Little Caesar, revealed to be Rizzo's older brother, and tells him the truth of Rizzo's death at the hands of Henry Addison in the Wilkinson home. Little Caesar was told Rizzo died of pneumonia.Shakes and Carol meet with Father Bobby and ask him to be Tommy and John's alibi for the night of the murder. Father Bobby doesn't want to swear to God and then lie on the stand. He asks why he should lie to let two guilty men, who will surely kill again, go free. He asks why Nokes' life means nothing to Shakes. Shakes tells him and Carol everything that happened while he, Michael, Tommy and John were at Wilkinson's. Afterward, Father Bobby says he has some thinking to do and tells them goodnight.In court, Michael successfully begins to throw the case, conveniently forgetting to present the jury with a motive. With the help of a list of questions and answers Michael previously provided him, Snyder successfully displays one of the witnesses as a \\\"scared woman who had too much to drink\\\", making it questionable whether Tommy and John were ever in the bar to begin with. Michael calls a character witness for Nokes by the name of Ralph Ferguson. Ferguson tells the jury that Nokes was a good man and didn't deserve to be killed by two street punks. Snyder uses Michael's question list to grill Ferguson on the goings-on of the Wilkinson Home for Boys. He asks him about the beatings and rapes and whether he and Nokes participated. Ferguson, realizing who the defendants are, breaks down and confesses. He's dismissed by the judge but told not to stray too far from home since there are people who will \\\"want to talk to him\\\".The next day Father Bobby gets on the stand, swears to tell the truth, and says that Tommy and John were with him at a Knicks game the night of the murder. Michael asks him if he has any proof. Father Bobby produces three ticket stubs.The jury finds Tommy and John not guilty.Addison's body is found in a swamp by La Guardia airport. Shot to death by Little Caesar's men. Adam Styler is arrested by internal affairs.The four friends and Carol meet for a private party. They share stories of their childhood and sing \\\"Walk Like a Man\\\" for Carol. Shakes' narration explains that this was the last night they would ever be together. Not long after that, John's body is found in an apartment stairway next to a bottle of booze that killed him. About a year after that, Tommy's body is found by the river with five bullets in his head. Both of them never reached thirty. Michael moves to England, becomes a carpenter, and never marries. Shakes still lives in Hell's Kitchen and writes for the paper. Carol is an unwed mother, compliments of John, and named her son John Michael Thomas. She calls him 'Shakes'.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"review_date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 3566,\n        \"samples\": [\n          \"18 August 2014\",\n          \"12 June 2014\",\n          \"30 April 2008\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"user_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4390,\n        \"samples\": [\n          \"ur18703917\",\n          \"ur1838392\",\n          \"ur15949031\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_spoiler\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false,\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"review_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5335,\n        \"samples\": [\n          \"Batman Forever. Personally, i don't like this title. Sounds...well....crap, and lame to be honest. Sounds like a kids movie. And guess what, it IS a kids movie. Before i lay into this film, I did find it entertaining. Both as a kid, and as an adult. But i didn't like it as a Batman film. It just doesn't capture the essence of what Burton created. In fact, it completely ignores it. It acts as more of a re-boot in a way. But the bottom line, its entertaining. Thats all that saves this.I don't understand why they got rid of Burton. His vision of Batman was brilliant. I also don't understand why they chose Joel Schumacher as his replacement. And i don't understand why they ruined a tremendous character in Two-Face. And I don't understand why.....you get the picture. Val Kilmer. Great actor. See The Doors for his best performance. See Batman Forever for his, well, not as good performance. Don't get me wrong, he was a good Batman. He's no Keaton, but he did well with what he had to work with. But none of the actors really shone in this. Nothing shone in this. Except the flashy neon signs in an equally flashy Gotham City. So, Schumacher thought, \\\"Ok i'm making a Batman film. Great. But how do i ruin it? I know, i'll put nipples on the suit. Yeah that'll do it. Oooh, and i'll make Two-Face a cheap Joker rip off. I know, i'll get Jim Carrey to dress in spandex and dance around and basically be...Jim Carrey. Oooooh, i'll also include a stupid sub-plot love story. I think thats it, i'll save my other ideas for the next one. Right, lets film!\\\" So they filmed. And here it is. Two-Face is a great, tragic character. Who rose to greatness, and then fell to tragedy. He isn't in this. He's a laughy stupid gimmicky character. Who jumps around in hysterics whenever there's an explosion. He's after revenge against Batman, because...well... no idea why. Batman didn't really do anything. So anyway, he teams up with The Riddler, who wants revenge against Bruce Wayne, because....he got fired from his company. How pathetic. Carrey and Tommy wasted their talents on this film. As did Kilmer, O'Donnell, Kidman, etc. Furthermore, Riddler aims to be the smartest man in the world by sucking up everyones brainwaves. (Cringe.) Anyhow, Batman must save the day. With a sidekick...Robin! I'm not a big fan of Robin. But i think the way they worked him into the film was pretty good. He's a young, troubled man who wants revenge. He's someone who Bruce can relate to. And tries to save Dick Grayson from choosing the path he chose, as during the film, he starts to regret, and wants a normal life. Which is another OKish moment in the film. I suppose.Overall, this film isn't particularly great. And i gave it a 6 mainly because i feel nostalgic when i see it. And its also entertaining. I wasn't bored when i watched it, then, or now. But I'll repeat what i said, I don't like it as a Batman film. You want Batman, check out the first one. That IS Batman.\",\n          \"Ever since \\\"Rise of the Planet of the apes\\\" was advertised, I've loved the direction this \\\"old worn out\\\" franchise is taking, and it seems a lot of other people are now on-board too. I mean, with the exception of \\\"Batman,\\\" what other franchise that's been \\\"rebooted\\\" was actually in dire need of it, and has actually pulled it off in a totally new, creative and original way? To get straight to the point. \\\"Dawn of the Planet of the apes\\\" is what \\\"The Dark Knight\\\" was to \\\"Batman begins.\\\" In that its successful in living up to the impossible expectations set-up after the surprise praise put upon number 1. If not completely surpassing those expectations.What worked for the best in \\\"rise\\\" is built upon with this one. Yes, Ceaser, the leader of all of these super intelligent apes is still the star of the show, brought to life with amazing motion capture CGI, and the under-praised actions of Andy Serkis. But what's going on around him is equally amazing. With the entire films special effects being at their best.There's a lot more use for the other apes this time as well, with the people behind their actions making some of the other characters equally as compelling As Caeser. But its still the story that comes first, and the film is made all the stronger for it. In the old movies you had to sustain disbelief a lot when it was just guys in rubber suits playing the apes, but here, you believe these characters are real when they act like apes, and completely forget your watching an animated animal when these guys are talking.The First movie had a couple of daft bits, but this one (surprising as it sounds) feels completely believable and not stupid at all. Its stories great and unpredictable, its effects are amazing, there's heartfelt moments, exciting moments,creepy moments,and even a few funny ones. With the whole thing being brought to life with modern, unique computer altered performances, that have to be seen to be believed.Maybe i'm being to generous, but I really can't praise this movie enough. Too call it a great sequel is un-fair because its more than that, and is possibly the first film i've seen in years that I may even add to my \\\"All time favourites.\\\" But is that all that surprising when \\\"Dawn\\\" is so damn near flawless.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rating_y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 1,\n        \"max\": 10,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          2,\n          9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"review_summary\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5233,\n        \"samples\": [\n          \"Hidden Role Models\",\n          \"A Guilty Pleasure\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"whole_review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5335,\n        \"samples\": [\n          \"Batman Forever. Personally, i don't like this title. Sounds...well....crap, and lame to be honest. Sounds like a kids movie. And guess what, it IS a kids movie. Before i lay into this film, I did find it entertaining. Both as a kid, and as an adult. But i didn't like it as a Batman film. It just doesn't capture the essence of what Burton created. In fact, it completely ignores it. It acts as more of a re-boot in a way. But the bottom line, its entertaining. Thats all that saves this.I don't understand why they got rid of Burton. His vision of Batman was brilliant. I also don't understand why they chose Joel Schumacher as his replacement. And i don't understand why they ruined a tremendous character in Two-Face. And I don't understand why.....you get the picture. Val Kilmer. Great actor. See The Doors for his best performance. See Batman Forever for his, well, not as good performance. Don't get me wrong, he was a good Batman. He's no Keaton, but he did well with what he had to work with. But none of the actors really shone in this. Nothing shone in this. Except the flashy neon signs in an equally flashy Gotham City. So, Schumacher thought, \\\"Ok i'm making a Batman film. Great. But how do i ruin it? I know, i'll put nipples on the suit. Yeah that'll do it. Oooh, and i'll make Two-Face a cheap Joker rip off. I know, i'll get Jim Carrey to dress in spandex and dance around and basically be...Jim Carrey. Oooooh, i'll also include a stupid sub-plot love story. I think thats it, i'll save my other ideas for the next one. Right, lets film!\\\" So they filmed. And here it is. Two-Face is a great, tragic character. Who rose to greatness, and then fell to tragedy. He isn't in this. He's a laughy stupid gimmicky character. Who jumps around in hysterics whenever there's an explosion. He's after revenge against Batman, because...well... no idea why. Batman didn't really do anything. So anyway, he teams up with The Riddler, who wants revenge against Bruce Wayne, because....he got fired from his company. How pathetic. Carrey and Tommy wasted their talents on this film. As did Kilmer, O'Donnell, Kidman, etc. Furthermore, Riddler aims to be the smartest man in the world by sucking up everyones brainwaves. (Cringe.) Anyhow, Batman must save the day. With a sidekick...Robin! I'm not a big fan of Robin. But i think the way they worked him into the film was pretty good. He's a young, troubled man who wants revenge. He's someone who Bruce can relate to. And tries to save Dick Grayson from choosing the path he chose, as during the film, he starts to regret, and wants a normal life. Which is another OKish moment in the film. I suppose.Overall, this film isn't particularly great. And i gave it a 6 mainly because i feel nostalgic when i see it. And its also entertaining. I wasn't bored when i watched it, then, or now. But I'll repeat what i said, I don't like it as a Batman film. You want Batman, check out the first one. That IS Batman.Bye bye Burton....Hello Schumacher.\",\n          \"Ever since \\\"Rise of the Planet of the apes\\\" was advertised, I've loved the direction this \\\"old worn out\\\" franchise is taking, and it seems a lot of other people are now on-board too. I mean, with the exception of \\\"Batman,\\\" what other franchise that's been \\\"rebooted\\\" was actually in dire need of it, and has actually pulled it off in a totally new, creative and original way? To get straight to the point. \\\"Dawn of the Planet of the apes\\\" is what \\\"The Dark Knight\\\" was to \\\"Batman begins.\\\" In that its successful in living up to the impossible expectations set-up after the surprise praise put upon number 1. If not completely surpassing those expectations.What worked for the best in \\\"rise\\\" is built upon with this one. Yes, Ceaser, the leader of all of these super intelligent apes is still the star of the show, brought to life with amazing motion capture CGI, and the under-praised actions of Andy Serkis. But what's going on around him is equally amazing. With the entire films special effects being at their best.There's a lot more use for the other apes this time as well, with the people behind their actions making some of the other characters equally as compelling As Caeser. But its still the story that comes first, and the film is made all the stronger for it. In the old movies you had to sustain disbelief a lot when it was just guys in rubber suits playing the apes, but here, you believe these characters are real when they act like apes, and completely forget your watching an animated animal when these guys are talking.The First movie had a couple of daft bits, but this one (surprising as it sounds) feels completely believable and not stupid at all. Its stories great and unpredictable, its effects are amazing, there's heartfelt moments, exciting moments,creepy moments,and even a few funny ones. With the whole thing being brought to life with modern, unique computer altered performances, that have to be seen to be believed.Maybe i'm being to generous, but I really can't praise this movie enough. Too call it a great sequel is un-fair because its more than that, and is possibly the first film i've seen in years that I may even add to my \\\"All time favourites.\\\" But is that all that surprising when \\\"Dawn\\\" is so damn near flawless.Has to be seen to be believed!!\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Loading the dataset from drive\n",
        "df = pd.read_csv(\"/content/drive/My Drive/DSC 514 NLP/sampled_data.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhUeo_1UGdgD"
      },
      "source": [
        "We will assign a unique ID to each review (review_id) before splitting the review:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "KEzi5TD2GZhF"
      },
      "outputs": [],
      "source": [
        "# Unique review ID to each row\n",
        "df['review_id'] = df.index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "WQwMbEm_G2Tl"
      },
      "outputs": [],
      "source": [
        "# Creating a HuggingFace dataset\n",
        "dataset = Dataset.from_pandas(df[['review_text', 'is_spoiler', 'review_id']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "znGx7keSHI1E"
      },
      "outputs": [],
      "source": [
        "# Loading the tokenizer for roberta from pretrained\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "# Next, this function will split the review into parts of 512 tokens each which is the maximum input for roberta\n",
        "# and will also keep the review_id and the label for each chunk created        \n",
        "\n",
        "def chunk_review(batch):\n",
        "    chunk_size = 512  # Maximum tokens allowed by RoBERTa\n",
        "    stride = 256  # Overlapping size for better context retention\n",
        "    all_chunks = []  # A list to store all results\n",
        "\n",
        "    # Looping through each row in the batch\n",
        "    for review_text, is_spoiler, review_id in zip(batch[\"review_text\"], batch[\"is_spoiler\"], batch[\"review_id\"]):\n",
        "        # Tokenizing with truncation and returning overflow tokens if necessary\n",
        "        tokens = tokenizer(review_text,\n",
        "                           return_overflowing_tokens=True,\n",
        "                           truncation=True,\n",
        "                           max_length=chunk_size,\n",
        "                           stride=stride)\n",
        "\n",
        "        input_ids_list = tokens[\"input_ids\"]\n",
        "        attention_mask_list = tokens[\"attention_mask\"]\n",
        "        \n",
        "        # Now, we split the review to chunks of size 512 max\n",
        "        for input_ids, attention_mask in zip(input_ids_list, attention_mask_list):\n",
        "            all_chunks.append({\n",
        "                \"review_id\": review_id,\n",
        "                \"input_ids\": input_ids,  # getting the id for the tokens, ensuring this is a list of integers (token IDs)\n",
        "                \"attention_mask\": attention_mask, # getting the attention mask\n",
        "                \"label\": is_spoiler\n",
        "            })\n",
        "\n",
        "    # Returning a dictionary of lists to fit the format of HuggingFace\n",
        "    return {\n",
        "        \"review_id\": [chunk[\"review_id\"] for chunk in all_chunks],\n",
        "        \"input_ids\": [chunk[\"input_ids\"] for chunk in all_chunks],  # Should be a list of lists\n",
        "        \"attention_mask\": [chunk[\"attention_mask\"] for chunk in all_chunks],\n",
        "        \"label\": [chunk[\"label\"] for chunk in all_chunks]\n",
        "    }\n",
        "\n",
        "# So now we can apply the chunking\n",
        "# changed batched to True since now we are returning a list\n",
        "dataset_chunked = dataset.map(chunk_review, batched=True, batch_size=1, remove_columns=[\"review_text\", \"is_spoiler\"])\n",
        "dataset_chunked = dataset_chunked.flatten_indices()\n",
        "```"
      ],
      "metadata": {
        "id": "9diT9IeUnIT_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset, Features, Sequence, Value\n",
        "\n",
        "def process_and_chunk(dataset):\n",
        "    chunk_size = 512\n",
        "    stride = 256\n",
        "    all_chunks = {\"review_id\": [], \"input_ids\": [], \"attention_mask\": [], \"label\": []}\n",
        "\n",
        "    for example in dataset:\n",
        "        review_text = example[\"review_text\"]\n",
        "        is_spoiler = example[\"is_spoiler\"]\n",
        "        review_id = example[\"review_id\"]\n",
        "\n",
        "        # Tokenizing the text with proper settings\n",
        "        tokens = tokenizer(\n",
        "            review_text,\n",
        "            padding=False,\n",
        "            truncation=True,\n",
        "            max_length=chunk_size,\n",
        "            stride=stride,\n",
        "            return_overflowing_tokens=True,\n",
        "            return_tensors=None\n",
        "        )\n",
        "\n",
        "        input_ids_list = tokens.get(\"input_ids\", [])\n",
        "        attention_mask_list = tokens.get(\"attention_mask\", [])\n",
        "\n",
        "        # If the tokenizer returns a single chunk instead of multiple\n",
        "        if isinstance(input_ids_list[0], int):\n",
        "            # Wrap it in a list to maintain uniformity\n",
        "            input_ids_list = [input_ids_list]\n",
        "            attention_mask_list = [attention_mask_list]\n",
        "\n",
        "        # Process each chunk\n",
        "        for input_ids, attention_mask in zip(input_ids_list, attention_mask_list):\n",
        "            all_chunks[\"review_id\"].append(review_id)\n",
        "            all_chunks[\"input_ids\"].append(input_ids)  # Store as a list of integers\n",
        "            all_chunks[\"attention_mask\"].append(attention_mask)  # Store as a list of integers\n",
        "            all_chunks[\"label\"].append(int(is_spoiler))\n",
        "\n",
        "    return all_chunks\n"
      ],
      "metadata": {
        "id": "3TCStURDkLlH"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Process the dataset manually\n",
        "\n",
        "features = Features({\n",
        "    'review_id': Value('int64'),\n",
        "    'input_ids': Sequence(Value('int32')),  # Forces input_ids to be stored as lists of integers\n",
        "    'attention_mask': Sequence(Value('int8')),  # Forces attention_mask to be stored as lists of integers\n",
        "    'label': Value('int64')\n",
        "})\n",
        "\n",
        "\n",
        "# Convert the dataset to a list of dictionaries for processing\n",
        "dataset_list = [dataset[i] for i in range(len(dataset))]\n",
        "\n",
        "# Process the dataset manually\n",
        "processed_chunks = process_and_chunk(dataset_list)\n",
        "\n",
        "# Create the dataset using the specified schema\n",
        "dataset_chunked = Dataset.from_dict(processed_chunks, features=features)\n"
      ],
      "metadata": {
        "id": "gAuS6hEtk6mG"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset_chunked.features)\n",
        "print(type(dataset_chunked['input_ids'][0]))  # Should be <class 'list'>\n",
        "print(type(dataset_chunked['input_ids'][0][0]))  # Should be <class 'int'>\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQAJHHLUmlDw",
        "outputId": "0a65c4be-e2db-4522-c961-b31d70b6db57"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'review_id': Value(dtype='int64', id=None), 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None), 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None), 'label': Value(dtype='int64', id=None)}\n",
            "<class 'list'>\n",
            "<class 'int'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oxq5Kb3cQgXA",
        "outputId": "862b7532-4d82-42aa-86e9-ebae01810649"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'review_id': 0, 'input_ids': [0, 7516, 147, 64, 38, 386, 15, 596, 1697, 28972, 197, 1183, 42, 822, 13, 7125, 116, 30800, 6, 24, 18, 95, 6269, 4, 45527, 6, 18606, 28291, 18, 2664, 3914, 2048, 16, 10, 4613, 410, 22650, 6, 61, 2386, 123, 7, 109, 5, 144, 10861, 17605, 19650, 821, 8299, 4, 497, 5, 276, 86, 6, 37, 18, 10, 8840, 2598, 6, 3030, 7, 146, 402, 9, 1003, 4, 9136, 6, 37, 7416, 9, 33884, 8, 5, 372, 1151, 77, 37, 5315, 1637, 6, 53, 15, 39, 9794, 7, 465, 5, 1637, 4691, 293, 6, 37, 6952, 13, 215, 3280, 383, 25, 20310, 6, 689, 36, 3983, 7022, 39, 9759, 8, 4441, 24, 13, 3630, 16, 10, 4187, 1310, 43, 8, 657, 36, 700, 14528, 5712, 13, 390, 54, 32, 95, 7209, 198, 123, 7, 146, 1531, 9, 123, 6, 8, 47, 64, 75, 244, 619, 13, 5, 2173, 43, 178, 6, 9, 768, 6, 358, 1310, 6, 358, 30146, 16, 888, 233, 9, 5, 527, 6, 98, 24, 18, 45, 95, 10, 651, 9, 7031, 1545, 12, 31586, 11248, 4, 85, 18, 67, 966, 19280, 14, 37, 18, 215, 10, 9256, 12576, 6, 37, 18, 2882, 7, 458, 5, 2441, 19, 39, 1029, 12, 16823, 8, 64, 304, 39, 2048, 7, 323, 49, 3423, 9, 12594, 15, 5, 2441, 4, 7516, 8, 5, 3558, 6, 19, 3090, 36, 627, 7626, 9, 5, 2393, 3914, 18, 15955, 43, 19023, 3009, 19, 20, 23914, 15556, 368, 36, 4771, 102, 28291, 18, 2048, 43, 8, 1747, 3064, 13, 123, 137, 5, 4817, 9, 18152, 14, 37, 18, 122, 10, 3228, 12, 4416, 9556, 492, 5, 527, 10, 45, 12, 15605, 12, 19530, 40955, 6, 45, 12, 15605, 12, 30132, 219, 3558, 14, 14905, 5, 1569, 16, 202, 10, 5313, 4187, 122, 6, 1812, 107, 71, 5, 822, 21, 156, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'label': 1}\n"
          ]
        }
      ],
      "source": [
        "print(dataset_chunked[0]) # this should not return nested lists"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(dataset_chunked))\n",
        "print(dataset_chunked.features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiWS6F3Pjz0x",
        "outputId": "2428459b-e728-4fda-8608-f84bfc0627b5"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'datasets.arrow_dataset.Dataset'>\n",
            "{'review_id': Value(dtype='int64', id=None), 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None), 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None), 'label': Value(dtype='int64', id=None)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "kZ8jhCCQLvWQ"
      },
      "outputs": [],
      "source": [
        "# Splitting after apllying the chunking using the train-test split from Dataset , we want to keep the review_id\n",
        "# First, split the dataset into train and test (e.g., 80% train, 20% test)\n",
        "\n",
        "train_val_dataset = dataset_chunked.train_test_split(test_size=0.2, seed=42)\n",
        "\n",
        "train_val_split = train_val_dataset['train'].train_test_split(test_size=0.1, seed=42)\n",
        "\n",
        "dataset_split = DatasetDict({\n",
        "    'train': train_val_split['train'],\n",
        "    'validation': train_val_split['test'],\n",
        "    'test': train_val_dataset['test']\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "jWrbBB-zNhWe"
      },
      "outputs": [],
      "source": [
        "# Formatting for Pytorch in order to convert these columns and be ready to used from Hugging Face\n",
        "dataset_split.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Accessing the 'input_ids' column directly\n",
        "token_lengths = [len(input_ids) if isinstance(input_ids, list) else None for input_ids in dataset_chunked['input_ids']]\n",
        "\n",
        "# Remove None values from token_lengths\n",
        "token_lengths = [length for length in token_lengths if length is not None]\n",
        "\n",
        "# Print the information\n",
        "print(f\"Total chunks: {len(token_lengths)}\")\n",
        "print(f\"Max token length in our chunks: {max(token_lengths)}\")\n",
        "print(f\"Chunks > 512: {sum(l > 512 for l in token_lengths)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLWa19HFj7ov",
        "outputId": "127dbed2-2dd7-426e-c66a-7626a5efdc19"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total chunks: 5335\n",
            "Max token length in our chunks: 512\n",
            "Chunks > 512: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zk4MQd3cLkg8",
        "outputId": "ba3ffd19-3239-4c7c-f7a4-8a0a343cc557"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total chunks: 5335\n",
            "Max token length in our chunks: 512\n",
            "Chunks > 512: 0\n"
          ]
        }
      ],
      "source": [
        "# Counting the token legths\n",
        "# Access the 'input_ids' column directly\n",
        "token_lengths = [len(input_ids) for input_ids in dataset_chunked['input_ids']]\n",
        "\n",
        "# Print the information\n",
        "print(f\"Total chunks: {len(token_lengths)}\")\n",
        "print(f\"Max token length in our chunks: {max(token_lengths)}\")\n",
        "print(f\"Chunks > 512: {sum(l > 512 for l in token_lengths)}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "v_eOtwLKNiHX",
        "outputId": "52bcaa78-98e0-4d39-809e-87f383819019"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# From the cell above we have verified that the splitting was performed correctly\n",
        "\n",
        "# Checking also with plot that indeed the tokens have length less than the maximum that roberta can take\n",
        "plt.hist(token_lengths, bins=30, color='skyblue', edgecolor='black')\n",
        "plt.axvline(x=600, color='red', linestyle='--', linewidth=2, label='512 Tokens Limit')\n",
        "plt.title('Token Lengths After Chunking')\n",
        "plt.xlabel('Token Length')\n",
        "plt.ylabel('Number of Chunks')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLbVHljgRmI5"
      },
      "source": [
        "From the plot above we can see that everything is working as we wanted, there are no chunks with length larger than 512. We can see a lot of smaller chunks and a spike at 512 where the longer reviews were splitted. Now we can load the roberta model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "HgI-c97FWTUw"
      },
      "outputs": [],
      "source": [
        "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
        "\n",
        "label2id = { \"non-spoiler\": 0,\"spoiler\": 1}\n",
        "id2label = {0: \"non-spoiler\",1: \"spoiler\"}\n",
        "\n",
        "model_name = \"roberta-base\"\n",
        "\n",
        "config = RobertaConfig.from_pretrained(\n",
        "    model_name,\n",
        "    output_hidden_states = False,\n",
        "    num_labels = 2,\n",
        "    label2id = label2id,\n",
        "    id2label = id2label )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgKsDX_2WTM-",
        "outputId": "cbe24b75-0a7e-4a60-f512-1e0fc72fd77a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Initializing the model\n",
        "model = RobertaForSequenceClassification.from_pretrained(model_name, config=config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "pi25uMujYyid"
      },
      "outputs": [],
      "source": [
        "# Batch size and gradient accumulation -> these can be changed if needed\n",
        "batch_size = 16\n",
        "gradient_accumulation_steps = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "v95_pqh1Yyfg"
      },
      "outputs": [],
      "source": [
        "# Logging steps\n",
        "logging_steps = len(dataset_split[\"train\"]) // (batch_size * gradient_accumulation_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "DUzm-VSDYyco"
      },
      "outputs": [],
      "source": [
        "# Directory to save output\n",
        "OUTPUT_DIR = \"./\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HijwYi7MawhV",
        "outputId": "8ab1d750-f448-42ac-c56c-73600a3a52b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of  Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Training arguments for roberta\n",
        "# we want to match the chunked dataset so we will modify the previous arguements\n",
        "\n",
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=os.path.join(OUTPUT_DIR, \"roberta-model\"),\n",
        "    evaluation_strategy=\"epoch\",                            # evaluate after every epoch\n",
        "    save_strategy=\"epoch\",                                  # and save\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=logging_steps,                            # we calculated this above\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
        "    num_train_epochs=3,                                   # number of epochs to train\n",
        "    learning_rate=2e-5,                                   # learning rate\n",
        "    weight_decay=0.02,                                    # weight decay\n",
        "    load_best_model_at_end=True,                          # we want to get the best model by validation loss\n",
        "    metric_for_best_model=\"eval_loss\",                    # metric to use will be eval_loss\n",
        "    greater_is_better=False,                              # we want to minimize the loss\n",
        "    save_total_limit=2,\n",
        "    logging_dir=\"./logs\",\n",
        "    fp16=True,                                             # Enable mixed-precision training to save memory\n",
        "    report_to=\"wandb\" )                                   # to use the Weights & Biases site"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y52TVxpUawbx",
        "outputId": "ddf5f890-3888-480c-9587-ed685177c1e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-54-5f33fad406cb>:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        }
      ],
      "source": [
        "# Trainer setup\n",
        "from transformers import Trainer, EarlyStoppingCallback\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset_split[\"train\"],\n",
        "    eval_dataset=dataset_split[\"validation\"],  # Use validation set for evaluation during training\n",
        "    tokenizer=tokenizer,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "7IX9itKFYyZl",
        "outputId": "bd7b2c30-9846-46b5-d2b0-7e341fca1b59"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='360' max='360' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [360/360 03:05, Epoch 2/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.646000</td>\n",
              "      <td>0.595947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.503700</td>\n",
              "      <td>0.598259</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=360, training_loss=0.5743415090772841, metrics={'train_runtime': 186.0667, 'train_samples_per_second': 61.929, 'train_steps_per_second': 1.935, 'total_flos': 3005248307656560.0, 'train_loss': 0.5743415090772841, 'epoch': 2.979253112033195})"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "# Finally, time to train\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "kiy1_XkSfvrq",
        "outputId": "d40749a9-f763-4437-c632-7cf8d2ea2ae0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        }
      ],
      "source": [
        "# After training to calculate the metrics\n",
        "\n",
        "# In order to predict on the test data\n",
        "y_test = dataset_split[\"test\"]\n",
        "preds_output = trainer.predict(dataset_split[\"test\"])\n",
        "y_preds = np.argmax(preds_output.predictions, axis=1)\n",
        "y_test = preds_output.label_ids"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1iTOfoCWfiz",
        "outputId": "80942842-617d-4280-87fd-33ee4ff5072d"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, ..., 1, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a8NYwb8KsUU",
        "outputId": "ec100b06-c4df-4883-84b6-78f430daa8bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score : 0.7171806167400882\n",
            "Accuracy : 0.6991565135895033\n",
            "Precision: 0.6806020066889632\n",
            "Recall   : 0.7579143389199255\n",
            "ROC AUC  : 0.6987684902146797\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.64      0.68       530\n",
            "           1       0.68      0.76      0.72       537\n",
            "\n",
            "    accuracy                           0.70      1067\n",
            "   macro avg       0.70      0.70      0.70      1067\n",
            "weighted avg       0.70      0.70      0.70      1067\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Metrics\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, roc_auc_score, classification_report\n",
        "\n",
        "# Evaluating\n",
        "print(f\"F1 Score : {f1_score(y_test, y_preds)}\")\n",
        "print(f\"Accuracy : {accuracy_score(y_test, y_preds)}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_preds)}\")\n",
        "print(f\"Recall   : {recall_score(y_test, y_preds)}\")\n",
        "print(f\"ROC AUC  : {roc_auc_score(y_test, y_preds)}\")\n",
        "print(classification_report(y_test, y_preds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XBADqR1fqyV",
        "outputId": "4666b3a5-f1c3-4427-f5f3-6dfa4f19a6ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:3309: UserWarning: `save_config` is deprecated and will be removed in v5 of Transformers. Use `is_main_process` instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model = trainer.model\n",
        "model.save_pretrained(os.path.join(OUTPUT_DIR, 'roberta-model/pretrained'), save_config=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKX__y5zhGmn"
      },
      "source": [
        "We evaluate and make predictions before aggregating.\n",
        "The function of trainer.predict() is run on the test set which is also splitted into chunks. We will now aggregate by the review id to see how many of the full reviews are considered spoilers."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check what columns are present in your test dataset\n",
        "print(dataset_split[\"test\"].column_names)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQ80GscDXQc2",
        "outputId": "7008b32f-3cca-4dd1-d40a-fa2b62b19dfe"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['review_id', 'input_ids', 'attention_mask', 'label']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting all review_ids as a list\n",
        "review_ids = dataset_split[\"test\"]['review_id']\n"
      ],
      "metadata": {
        "id": "qZomhv4sXio8"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the keys of a single row\n",
        "print(dataset_split[\"test\"][0].keys())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iY5non5pXtgw",
        "outputId": "2bffde59-4384-4ad9-f010-f2c672939e65"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['input_ids', 'attention_mask', 'label'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "review_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIQAZ5k2XjS4",
        "outputId": "e46377cf-6f35-42b8-b3b9-7fb3707316b0"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4384,\n",
              " 2140,\n",
              " 3189,\n",
              " 1543,\n",
              " 1481,\n",
              " 5016,\n",
              " 4854,\n",
              " 4461,\n",
              " 956,\n",
              " 1183,\n",
              " 863,\n",
              " 2985,\n",
              " 5027,\n",
              " 1433,\n",
              " 2558,\n",
              " 4099,\n",
              " 4929,\n",
              " 4885,\n",
              " 4122,\n",
              " 1962,\n",
              " 4863,\n",
              " 265,\n",
              " 1552,\n",
              " 5293,\n",
              " 3969,\n",
              " 2234,\n",
              " 2865,\n",
              " 2862,\n",
              " 2018,\n",
              " 3353,\n",
              " 2437,\n",
              " 5151,\n",
              " 4743,\n",
              " 1888,\n",
              " 324,\n",
              " 3202,\n",
              " 930,\n",
              " 4691,\n",
              " 3103,\n",
              " 3951,\n",
              " 672,\n",
              " 5159,\n",
              " 954,\n",
              " 1712,\n",
              " 497,\n",
              " 3301,\n",
              " 1158,\n",
              " 2370,\n",
              " 1725,\n",
              " 3934,\n",
              " 815,\n",
              " 1235,\n",
              " 1131,\n",
              " 3486,\n",
              " 4938,\n",
              " 2011,\n",
              " 820,\n",
              " 770,\n",
              " 3050,\n",
              " 3939,\n",
              " 2967,\n",
              " 1063,\n",
              " 3666,\n",
              " 5120,\n",
              " 854,\n",
              " 1244,\n",
              " 233,\n",
              " 2304,\n",
              " 4480,\n",
              " 1715,\n",
              " 3993,\n",
              " 983,\n",
              " 1280,\n",
              " 1528,\n",
              " 245,\n",
              " 2195,\n",
              " 39,\n",
              " 3812,\n",
              " 1935,\n",
              " 2346,\n",
              " 4602,\n",
              " 3724,\n",
              " 517,\n",
              " 330,\n",
              " 2308,\n",
              " 665,\n",
              " 751,\n",
              " 3998,\n",
              " 1843,\n",
              " 1856,\n",
              " 4252,\n",
              " 1821,\n",
              " 2091,\n",
              " 5087,\n",
              " 4532,\n",
              " 3342,\n",
              " 1961,\n",
              " 1921,\n",
              " 4902,\n",
              " 4404,\n",
              " 4546,\n",
              " 5317,\n",
              " 2981,\n",
              " 4328,\n",
              " 5295,\n",
              " 1592,\n",
              " 2953,\n",
              " 1148,\n",
              " 2843,\n",
              " 429,\n",
              " 127,\n",
              " 1072,\n",
              " 2222,\n",
              " 285,\n",
              " 2888,\n",
              " 3051,\n",
              " 941,\n",
              " 643,\n",
              " 871,\n",
              " 1204,\n",
              " 3234,\n",
              " 609,\n",
              " 896,\n",
              " 724,\n",
              " 1324,\n",
              " 3880,\n",
              " 5055,\n",
              " 986,\n",
              " 1334,\n",
              " 2690,\n",
              " 2036,\n",
              " 2470,\n",
              " 3463,\n",
              " 3968,\n",
              " 293,\n",
              " 2566,\n",
              " 2595,\n",
              " 2519,\n",
              " 223,\n",
              " 5262,\n",
              " 350,\n",
              " 381,\n",
              " 656,\n",
              " 4475,\n",
              " 2823,\n",
              " 1389,\n",
              " 1834,\n",
              " 530,\n",
              " 4752,\n",
              " 4420,\n",
              " 5320,\n",
              " 677,\n",
              " 4037,\n",
              " 195,\n",
              " 5002,\n",
              " 757,\n",
              " 777,\n",
              " 4200,\n",
              " 4011,\n",
              " 3373,\n",
              " 3539,\n",
              " 2008,\n",
              " 208,\n",
              " 3604,\n",
              " 735,\n",
              " 5138,\n",
              " 3530,\n",
              " 1352,\n",
              " 2889,\n",
              " 1491,\n",
              " 3409,\n",
              " 1865,\n",
              " 3143,\n",
              " 2049,\n",
              " 2211,\n",
              " 453,\n",
              " 16,\n",
              " 3738,\n",
              " 2618,\n",
              " 1071,\n",
              " 5254,\n",
              " 2375,\n",
              " 2349,\n",
              " 37,\n",
              " 1699,\n",
              " 3835,\n",
              " 4289,\n",
              " 3684,\n",
              " 2059,\n",
              " 1912,\n",
              " 1539,\n",
              " 1660,\n",
              " 4330,\n",
              " 400,\n",
              " 5141,\n",
              " 2920,\n",
              " 775,\n",
              " 1218,\n",
              " 2118,\n",
              " 3455,\n",
              " 4448,\n",
              " 960,\n",
              " 5063,\n",
              " 2363,\n",
              " 2831,\n",
              " 3581,\n",
              " 455,\n",
              " 278,\n",
              " 929,\n",
              " 3920,\n",
              " 1812,\n",
              " 4991,\n",
              " 3967,\n",
              " 783,\n",
              " 2508,\n",
              " 4714,\n",
              " 1700,\n",
              " 420,\n",
              " 3086,\n",
              " 4817,\n",
              " 1624,\n",
              " 3052,\n",
              " 2128,\n",
              " 4899,\n",
              " 2584,\n",
              " 5145,\n",
              " 617,\n",
              " 3365,\n",
              " 80,\n",
              " 1777,\n",
              " 4945,\n",
              " 2705,\n",
              " 580,\n",
              " 490,\n",
              " 2228,\n",
              " 4821,\n",
              " 488,\n",
              " 4348,\n",
              " 4528,\n",
              " 5060,\n",
              " 1648,\n",
              " 3177,\n",
              " 2796,\n",
              " 2082,\n",
              " 4865,\n",
              " 3421,\n",
              " 1082,\n",
              " 4740,\n",
              " 2995,\n",
              " 419,\n",
              " 1306,\n",
              " 5124,\n",
              " 2684,\n",
              " 4166,\n",
              " 4897,\n",
              " 8,\n",
              " 3462,\n",
              " 2197,\n",
              " 2235,\n",
              " 4867,\n",
              " 2675,\n",
              " 2601,\n",
              " 4358,\n",
              " 3753,\n",
              " 2678,\n",
              " 4911,\n",
              " 3619,\n",
              " 4677,\n",
              " 4310,\n",
              " 3448,\n",
              " 2471,\n",
              " 3474,\n",
              " 2835,\n",
              " 5247,\n",
              " 4835,\n",
              " 2472,\n",
              " 2327,\n",
              " 3372,\n",
              " 4805,\n",
              " 624,\n",
              " 2000,\n",
              " 4550,\n",
              " 2095,\n",
              " 4193,\n",
              " 1636,\n",
              " 782,\n",
              " 2330,\n",
              " 4230,\n",
              " 4983,\n",
              " 551,\n",
              " 4296,\n",
              " 4318,\n",
              " 1165,\n",
              " 898,\n",
              " 3996,\n",
              " 5046,\n",
              " 4787,\n",
              " 1010,\n",
              " 5300,\n",
              " 3399,\n",
              " 619,\n",
              " 2938,\n",
              " 4593,\n",
              " 4278,\n",
              " 2651,\n",
              " 1438,\n",
              " 502,\n",
              " 1475,\n",
              " 1760,\n",
              " 3615,\n",
              " 1718,\n",
              " 2986,\n",
              " 3661,\n",
              " 1695,\n",
              " 3594,\n",
              " 4880,\n",
              " 4530,\n",
              " 2973,\n",
              " 3693,\n",
              " 4305,\n",
              " 769,\n",
              " 3180,\n",
              " 1034,\n",
              " 1145,\n",
              " 1478,\n",
              " 1270,\n",
              " 1116,\n",
              " 5235,\n",
              " 2956,\n",
              " 3097,\n",
              " 2502,\n",
              " 3647,\n",
              " 2415,\n",
              " 1527,\n",
              " 2287,\n",
              " 3060,\n",
              " 2086,\n",
              " 1119,\n",
              " 1135,\n",
              " 4952,\n",
              " 2277,\n",
              " 4716,\n",
              " 683,\n",
              " 4049,\n",
              " 1531,\n",
              " 2657,\n",
              " 1168,\n",
              " 2716,\n",
              " 2772,\n",
              " 592,\n",
              " 3716,\n",
              " 3489,\n",
              " 4477,\n",
              " 4632,\n",
              " 2996,\n",
              " 90,\n",
              " 3512,\n",
              " 880,\n",
              " 4692,\n",
              " 4002,\n",
              " 4297,\n",
              " 456,\n",
              " 4076,\n",
              " 1785,\n",
              " 430,\n",
              " 1512,\n",
              " 877,\n",
              " 4827,\n",
              " 3746,\n",
              " 903,\n",
              " 1031,\n",
              " 1417,\n",
              " 3332,\n",
              " 1412,\n",
              " 56,\n",
              " 2639,\n",
              " 3150,\n",
              " 4048,\n",
              " 2969,\n",
              " 2867,\n",
              " 4937,\n",
              " 181,\n",
              " 2989,\n",
              " 1930,\n",
              " 889,\n",
              " 156,\n",
              " 1103,\n",
              " 660,\n",
              " 3338,\n",
              " 4118,\n",
              " 3310,\n",
              " 2108,\n",
              " 1926,\n",
              " 925,\n",
              " 709,\n",
              " 2302,\n",
              " 4504,\n",
              " 1397,\n",
              " 1839,\n",
              " 2702,\n",
              " 3795,\n",
              " 2626,\n",
              " 4664,\n",
              " 1430,\n",
              " 4588,\n",
              " 756,\n",
              " 2780,\n",
              " 2825,\n",
              " 2301,\n",
              " 2114,\n",
              " 3830,\n",
              " 4052,\n",
              " 1714,\n",
              " 4374,\n",
              " 743,\n",
              " 2016,\n",
              " 2134,\n",
              " 4996,\n",
              " 3669,\n",
              " 4893,\n",
              " 4332,\n",
              " 47,\n",
              " 2738,\n",
              " 2162,\n",
              " 4812,\n",
              " 3041,\n",
              " 3418,\n",
              " 3430,\n",
              " 4932,\n",
              " 1141,\n",
              " 4778,\n",
              " 3407,\n",
              " 2014,\n",
              " 3928,\n",
              " 1939,\n",
              " 3845,\n",
              " 2193,\n",
              " 96,\n",
              " 3723,\n",
              " 1112,\n",
              " 1717,\n",
              " 2001,\n",
              " 387,\n",
              " 5284,\n",
              " 398,\n",
              " 4560,\n",
              " 720,\n",
              " 4539,\n",
              " 2721,\n",
              " 4245,\n",
              " 3755,\n",
              " 1092,\n",
              " 3381,\n",
              " 1359,\n",
              " 2023,\n",
              " 5117,\n",
              " 1332,\n",
              " 3473,\n",
              " 612,\n",
              " 4482,\n",
              " 4775,\n",
              " 3602,\n",
              " 2181,\n",
              " 122,\n",
              " 5105,\n",
              " 2880,\n",
              " 4102,\n",
              " 457,\n",
              " 4540,\n",
              " 4768,\n",
              " 1308,\n",
              " 108,\n",
              " 1759,\n",
              " 476,\n",
              " 3979,\n",
              " 3864,\n",
              " 3449,\n",
              " 5316,\n",
              " 5104,\n",
              " 2032,\n",
              " 368,\n",
              " 2711,\n",
              " 130,\n",
              " 5208,\n",
              " 4169,\n",
              " 1000,\n",
              " 151,\n",
              " 1666,\n",
              " 3433,\n",
              " 1483,\n",
              " 3655,\n",
              " 2553,\n",
              " 4488,\n",
              " 2682,\n",
              " 3317,\n",
              " 1859,\n",
              " 2350,\n",
              " 4424,\n",
              " 519,\n",
              " 4098,\n",
              " 234,\n",
              " 2530,\n",
              " 1945,\n",
              " 2895,\n",
              " 1384,\n",
              " 4534,\n",
              " 2126,\n",
              " 2828,\n",
              " 5311,\n",
              " 3855,\n",
              " 1401,\n",
              " 3754,\n",
              " 3389,\n",
              " 2427,\n",
              " 4152,\n",
              " 3394,\n",
              " 3550,\n",
              " 4665,\n",
              " 719,\n",
              " 3167,\n",
              " 621,\n",
              " 1441,\n",
              " 2819,\n",
              " 3793,\n",
              " 2755,\n",
              " 3618,\n",
              " 2729,\n",
              " 4044,\n",
              " 535,\n",
              " 1093,\n",
              " 129,\n",
              " 2640,\n",
              " 2105,\n",
              " 3852,\n",
              " 365,\n",
              " 475,\n",
              " 3367,\n",
              " 1799,\n",
              " 5095,\n",
              " 4984,\n",
              " 433,\n",
              " 451,\n",
              " 416,\n",
              " 5062,\n",
              " 2787,\n",
              " 5132,\n",
              " 2240,\n",
              " 161,\n",
              " 3147,\n",
              " 3136,\n",
              " 4671,\n",
              " 3291,\n",
              " 2887,\n",
              " 812,\n",
              " 361,\n",
              " 5277,\n",
              " 3885,\n",
              " 3707,\n",
              " 890,\n",
              " 2244,\n",
              " 4344,\n",
              " 1982,\n",
              " 4019,\n",
              " 31,\n",
              " 2005,\n",
              " 1414,\n",
              " 651,\n",
              " 1329,\n",
              " 1634,\n",
              " 1174,\n",
              " 4379,\n",
              " 4104,\n",
              " 3264,\n",
              " 418,\n",
              " 5128,\n",
              " 4927,\n",
              " 3540,\n",
              " 4282,\n",
              " 3568,\n",
              " 82,\n",
              " 712,\n",
              " 17,\n",
              " 866,\n",
              " 3119,\n",
              " 4458,\n",
              " 2251,\n",
              " 623,\n",
              " 3410,\n",
              " 5200,\n",
              " 3598,\n",
              " 2766,\n",
              " 2602,\n",
              " 1612,\n",
              " 5331,\n",
              " 2725,\n",
              " 3986,\n",
              " 3393,\n",
              " 4703,\n",
              " 4749,\n",
              " 1694,\n",
              " 5153,\n",
              " 604,\n",
              " 1277,\n",
              " 2432,\n",
              " 4130,\n",
              " 1163,\n",
              " 1498,\n",
              " 4756,\n",
              " 336,\n",
              " 5000,\n",
              " 1879,\n",
              " 1854,\n",
              " 2896,\n",
              " 4300,\n",
              " 4694,\n",
              " 795,\n",
              " 4218,\n",
              " 4315,\n",
              " 3824,\n",
              " 3034,\n",
              " 3893,\n",
              " 3553,\n",
              " 3492,\n",
              " 4179,\n",
              " 3547,\n",
              " 466,\n",
              " 4551,\n",
              " 3674,\n",
              " 1021,\n",
              " 359,\n",
              " 2624,\n",
              " 3327,\n",
              " 2289,\n",
              " 895,\n",
              " 3149,\n",
              " 3827,\n",
              " 5064,\n",
              " 5309,\n",
              " 797,\n",
              " 3190,\n",
              " 4887,\n",
              " 1044,\n",
              " 2811,\n",
              " 1391,\n",
              " 3347,\n",
              " 2713,\n",
              " 3607,\n",
              " 1152,\n",
              " 2451,\n",
              " 557,\n",
              " 2959,\n",
              " 1409,\n",
              " 4640,\n",
              " 792,\n",
              " 5080,\n",
              " 3309,\n",
              " 4657,\n",
              " 4151,\n",
              " 779,\n",
              " 4628,\n",
              " 1230,\n",
              " 3008,\n",
              " 5129,\n",
              " 1402,\n",
              " 3054,\n",
              " 1009,\n",
              " 2972,\n",
              " 2034,\n",
              " 240,\n",
              " 4987,\n",
              " 1563,\n",
              " 4547,\n",
              " 1509,\n",
              " 3535,\n",
              " 73,\n",
              " 4770,\n",
              " 2951,\n",
              " 4941,\n",
              " 4481,\n",
              " 3631,\n",
              " 4521,\n",
              " 1704,\n",
              " 4568,\n",
              " 1431,\n",
              " 3348,\n",
              " 3461,\n",
              " 1186,\n",
              " 3656,\n",
              " 1228,\n",
              " 2976,\n",
              " 2223,\n",
              " 4119,\n",
              " 2098,\n",
              " 2980,\n",
              " 3652,\n",
              " 1170,\n",
              " 106,\n",
              " 1868,\n",
              " 935,\n",
              " 4426,\n",
              " 1973,\n",
              " 100,\n",
              " 4847,\n",
              " 622,\n",
              " 1149,\n",
              " 1570,\n",
              " 2532,\n",
              " 4033,\n",
              " 4683,\n",
              " 3432,\n",
              " 3371,\n",
              " 3913,\n",
              " 4673,\n",
              " 2146,\n",
              " 3002,\n",
              " 585,\n",
              " 4858,\n",
              " 1185,\n",
              " 1534,\n",
              " 1269,\n",
              " 2386,\n",
              " 1495,\n",
              " 2145,\n",
              " 1416,\n",
              " 3483,\n",
              " 2002,\n",
              " 441,\n",
              " 2382,\n",
              " 5227,\n",
              " 102,\n",
              " 2620,\n",
              " 1554,\n",
              " 2726,\n",
              " 4670,\n",
              " 1418,\n",
              " 4739,\n",
              " 2178,\n",
              " 2914,\n",
              " 174,\n",
              " 2341,\n",
              " 5268,\n",
              " 2454,\n",
              " 3531,\n",
              " 910,\n",
              " 3565,\n",
              " 1519,\n",
              " 3294,\n",
              " 3274,\n",
              " 1633,\n",
              " 4000,\n",
              " 272,\n",
              " 4934,\n",
              " 2915,\n",
              " 4163,\n",
              " 4474,\n",
              " 4908,\n",
              " 4574,\n",
              " 1880,\n",
              " 4860,\n",
              " 72,\n",
              " 1089,\n",
              " 828,\n",
              " 4519,\n",
              " 2504,\n",
              " 2605,\n",
              " 5191,\n",
              " 4501,\n",
              " 846,\n",
              " 1427,\n",
              " 1055,\n",
              " 4444,\n",
              " 1946,\n",
              " 452,\n",
              " 3883,\n",
              " 1012,\n",
              " 3255,\n",
              " 4354,\n",
              " 1464,\n",
              " 4377,\n",
              " 1446,\n",
              " 2286,\n",
              " 1766,\n",
              " 4614,\n",
              " 4818,\n",
              " 3597,\n",
              " 5067,\n",
              " 178,\n",
              " 212,\n",
              " 1953,\n",
              " 2573,\n",
              " 404,\n",
              " 2760,\n",
              " 628,\n",
              " 5211,\n",
              " 2732,\n",
              " 1670,\n",
              " 2309,\n",
              " 883,\n",
              " 1087,\n",
              " 4313,\n",
              " 2333,\n",
              " 4850,\n",
              " 3668,\n",
              " 3777,\n",
              " 158,\n",
              " 3752,\n",
              " 3784,\n",
              " 292,\n",
              " 2424,\n",
              " 1662,\n",
              " 1435,\n",
              " 2089,\n",
              " 4915,\n",
              " 3853,\n",
              " 2212,\n",
              " 1779,\n",
              " 3829,\n",
              " 2042,\n",
              " 3733,\n",
              " 5230,\n",
              " 1677,\n",
              " 522,\n",
              " 1783,\n",
              " 4776,\n",
              " 2767,\n",
              " 904,\n",
              " 3329,\n",
              " 1436,\n",
              " 210,\n",
              " 2465,\n",
              " 3705,\n",
              " 3271,\n",
              " 1707,\n",
              " 1463,\n",
              " 531,\n",
              " 3450,\n",
              " 275,\n",
              " 2200,\n",
              " 2242,\n",
              " 5329,\n",
              " 922,\n",
              " 2599,\n",
              " 3224,\n",
              " 5269,\n",
              " 1226,\n",
              " 3069,\n",
              " 2143,\n",
              " 352,\n",
              " 682,\n",
              " 4061,\n",
              " 3917,\n",
              " 3212,\n",
              " 591,\n",
              " 4222,\n",
              " 1032,\n",
              " 3787,\n",
              " 663,\n",
              " 2293,\n",
              " 1144,\n",
              " 5212,\n",
              " 5037,\n",
              " 5207,\n",
              " 870,\n",
              " 5172,\n",
              " 1847,\n",
              " 1877,\n",
              " 1730,\n",
              " 4148,\n",
              " 367,\n",
              " 4734,\n",
              " 2273,\n",
              " 2227,\n",
              " 3153,\n",
              " 1099,\n",
              " 4322,\n",
              " 5084,\n",
              " 969,\n",
              " 1291,\n",
              " 3160,\n",
              " 2270,\n",
              " 1889,\n",
              " 4651,\n",
              " 11,\n",
              " 3359,\n",
              " 354,\n",
              " 2161,\n",
              " 686,\n",
              " 3019,\n",
              " 4678,\n",
              " 1849,\n",
              " 99,\n",
              " 2734,\n",
              " 4123,\n",
              " 3762,\n",
              " 3316,\n",
              " 4699,\n",
              " 940,\n",
              " 1701,\n",
              " 4848,\n",
              " 765,\n",
              " 5197,\n",
              " 3802,\n",
              " 3843,\n",
              " 3258,\n",
              " 5003,\n",
              " 1138,\n",
              " 1160,\n",
              " 2590,\n",
              " 30,\n",
              " 88,\n",
              " 907,\n",
              " 4471,\n",
              " 2429,\n",
              " 5181,\n",
              " 2400,\n",
              " 774,\n",
              " 1422,\n",
              " 638,\n",
              " 3886,\n",
              " 192,\n",
              " 4204,\n",
              " 3137,\n",
              " 3621,\n",
              " 3379,\n",
              " 4478,\n",
              " 4659,\n",
              " 4744,\n",
              " 2603,\n",
              " 2262,\n",
              " 3030,\n",
              " 3616,\n",
              " 3093,\n",
              " 5169,\n",
              " 3541,\n",
              " 5056,\n",
              " 680,\n",
              " 5260,\n",
              " 951,\n",
              " 1914,\n",
              " 3518,\n",
              " 4855,\n",
              " 5152,\n",
              " 1806,\n",
              " 5180,\n",
              " 191,\n",
              " 4272,\n",
              " 3542,\n",
              " 3439,\n",
              " 5306,\n",
              " 5098,\n",
              " 237,\n",
              " 2757,\n",
              " 1221,\n",
              " 1782,\n",
              " 4198,\n",
              " 1999,\n",
              " 681,\n",
              " 3940,\n",
              " 1276,\n",
              " 3575,\n",
              " 4825,\n",
              " 4057,\n",
              " 5253,\n",
              " 3905,\n",
              " 4436,\n",
              " 3980,\n",
              " 654,\n",
              " 4059,\n",
              " 2551,\n",
              " 1582,\n",
              " 933,\n",
              " 4794,\n",
              " 248,\n",
              " 739,\n",
              " 1225,\n",
              " 2982,\n",
              " 2902,\n",
              " 3223,\n",
              " 499,\n",
              " 4173,\n",
              " 864,\n",
              " 2850,\n",
              " 13,\n",
              " 5143,\n",
              " 3080,\n",
              " 3460,\n",
              " 763,\n",
              " 337,\n",
              " 4636,\n",
              " 2514,\n",
              " 3544,\n",
              " 3915,\n",
              " 3809,\n",
              " 3413,\n",
              " 2692,\n",
              " 4704,\n",
              " 5170,\n",
              " 3918,\n",
              " 2940,\n",
              " 5252,\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnSpdPcKfquy",
        "outputId": "0a4fbc8e-0318-4d6b-9ef9-c854c2062d49"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 4384,\n",
              " 1: 2140,\n",
              " 2: 3189,\n",
              " 3: 1543,\n",
              " 4: 1481,\n",
              " 5: 5016,\n",
              " 6: 4854,\n",
              " 7: 4461,\n",
              " 8: 956,\n",
              " 9: 1183,\n",
              " 10: 863,\n",
              " 11: 2985,\n",
              " 12: 5027,\n",
              " 13: 1433,\n",
              " 14: 2558,\n",
              " 15: 4099,\n",
              " 16: 4929,\n",
              " 17: 4885,\n",
              " 18: 4122,\n",
              " 19: 1962,\n",
              " 20: 4863,\n",
              " 21: 265,\n",
              " 22: 1552,\n",
              " 23: 5293,\n",
              " 24: 3969,\n",
              " 25: 2234,\n",
              " 26: 2865,\n",
              " 27: 2862,\n",
              " 28: 2018,\n",
              " 29: 3353,\n",
              " 30: 2437,\n",
              " 31: 5151,\n",
              " 32: 4743,\n",
              " 33: 1888,\n",
              " 34: 324,\n",
              " 35: 3202,\n",
              " 36: 930,\n",
              " 37: 4691,\n",
              " 38: 3103,\n",
              " 39: 3951,\n",
              " 40: 672,\n",
              " 41: 5159,\n",
              " 42: 954,\n",
              " 43: 1712,\n",
              " 44: 497,\n",
              " 45: 3301,\n",
              " 46: 1158,\n",
              " 47: 2370,\n",
              " 48: 1725,\n",
              " 49: 3934,\n",
              " 50: 815,\n",
              " 51: 1235,\n",
              " 52: 1131,\n",
              " 53: 3486,\n",
              " 54: 4938,\n",
              " 55: 2011,\n",
              " 56: 820,\n",
              " 57: 770,\n",
              " 58: 3050,\n",
              " 59: 3939,\n",
              " 60: 2967,\n",
              " 61: 1063,\n",
              " 62: 3666,\n",
              " 63: 5120,\n",
              " 64: 854,\n",
              " 65: 1244,\n",
              " 66: 233,\n",
              " 67: 2304,\n",
              " 68: 4480,\n",
              " 69: 1715,\n",
              " 70: 3993,\n",
              " 71: 983,\n",
              " 72: 1280,\n",
              " 73: 1528,\n",
              " 74: 245,\n",
              " 75: 2195,\n",
              " 76: 39,\n",
              " 77: 3812,\n",
              " 78: 1935,\n",
              " 79: 2346,\n",
              " 80: 4602,\n",
              " 81: 3724,\n",
              " 82: 517,\n",
              " 83: 330,\n",
              " 84: 2308,\n",
              " 85: 665,\n",
              " 86: 751,\n",
              " 87: 3998,\n",
              " 88: 1843,\n",
              " 89: 1856,\n",
              " 90: 4252,\n",
              " 91: 1821,\n",
              " 92: 2091,\n",
              " 93: 5087,\n",
              " 94: 4532,\n",
              " 95: 3342,\n",
              " 96: 1961,\n",
              " 97: 1921,\n",
              " 98: 4902,\n",
              " 99: 4404,\n",
              " 100: 4546,\n",
              " 101: 5317,\n",
              " 102: 2981,\n",
              " 103: 4328,\n",
              " 104: 5295,\n",
              " 105: 1592,\n",
              " 106: 2953,\n",
              " 107: 1148,\n",
              " 108: 2843,\n",
              " 109: 429,\n",
              " 110: 127,\n",
              " 111: 1072,\n",
              " 112: 2222,\n",
              " 113: 285,\n",
              " 114: 2888,\n",
              " 115: 3051,\n",
              " 116: 941,\n",
              " 117: 643,\n",
              " 118: 871,\n",
              " 119: 1204,\n",
              " 120: 3234,\n",
              " 121: 609,\n",
              " 122: 896,\n",
              " 123: 724,\n",
              " 124: 1324,\n",
              " 125: 3880,\n",
              " 126: 5055,\n",
              " 127: 986,\n",
              " 128: 1334,\n",
              " 129: 2690,\n",
              " 130: 2036,\n",
              " 131: 2470,\n",
              " 132: 3463,\n",
              " 133: 3968,\n",
              " 134: 293,\n",
              " 135: 2566,\n",
              " 136: 2595,\n",
              " 137: 2519,\n",
              " 138: 223,\n",
              " 139: 5262,\n",
              " 140: 350,\n",
              " 141: 381,\n",
              " 142: 656,\n",
              " 143: 4475,\n",
              " 144: 2823,\n",
              " 145: 1389,\n",
              " 146: 1834,\n",
              " 147: 530,\n",
              " 148: 4752,\n",
              " 149: 4420,\n",
              " 150: 5320,\n",
              " 151: 677,\n",
              " 152: 4037,\n",
              " 153: 195,\n",
              " 154: 5002,\n",
              " 155: 757,\n",
              " 156: 777,\n",
              " 157: 4200,\n",
              " 158: 4011,\n",
              " 159: 3373,\n",
              " 160: 3539,\n",
              " 161: 2008,\n",
              " 162: 208,\n",
              " 163: 3604,\n",
              " 164: 735,\n",
              " 165: 5138,\n",
              " 166: 3530,\n",
              " 167: 1352,\n",
              " 168: 2889,\n",
              " 169: 1491,\n",
              " 170: 3409,\n",
              " 171: 1865,\n",
              " 172: 3143,\n",
              " 173: 2049,\n",
              " 174: 2211,\n",
              " 175: 453,\n",
              " 176: 16,\n",
              " 177: 3738,\n",
              " 178: 2618,\n",
              " 179: 1071,\n",
              " 180: 5254,\n",
              " 181: 2375,\n",
              " 182: 2349,\n",
              " 183: 37,\n",
              " 184: 1699,\n",
              " 185: 3835,\n",
              " 186: 4289,\n",
              " 187: 3684,\n",
              " 188: 2059,\n",
              " 189: 1912,\n",
              " 190: 1539,\n",
              " 191: 1660,\n",
              " 192: 4330,\n",
              " 193: 400,\n",
              " 194: 5141,\n",
              " 195: 2920,\n",
              " 196: 775,\n",
              " 197: 1218,\n",
              " 198: 2118,\n",
              " 199: 3455,\n",
              " 200: 4448,\n",
              " 201: 960,\n",
              " 202: 5063,\n",
              " 203: 2363,\n",
              " 204: 2831,\n",
              " 205: 3581,\n",
              " 206: 455,\n",
              " 207: 278,\n",
              " 208: 929,\n",
              " 209: 3920,\n",
              " 210: 1812,\n",
              " 211: 4991,\n",
              " 212: 3967,\n",
              " 213: 783,\n",
              " 214: 2508,\n",
              " 215: 4714,\n",
              " 216: 1700,\n",
              " 217: 420,\n",
              " 218: 3086,\n",
              " 219: 4817,\n",
              " 220: 1624,\n",
              " 221: 3052,\n",
              " 222: 2128,\n",
              " 223: 4899,\n",
              " 224: 2584,\n",
              " 225: 5145,\n",
              " 226: 617,\n",
              " 227: 3365,\n",
              " 228: 80,\n",
              " 229: 1777,\n",
              " 230: 4945,\n",
              " 231: 2705,\n",
              " 232: 580,\n",
              " 233: 490,\n",
              " 234: 2228,\n",
              " 235: 4821,\n",
              " 236: 488,\n",
              " 237: 4348,\n",
              " 238: 4528,\n",
              " 239: 5060,\n",
              " 240: 1648,\n",
              " 241: 3177,\n",
              " 242: 2796,\n",
              " 243: 2082,\n",
              " 244: 4865,\n",
              " 245: 3421,\n",
              " 246: 1082,\n",
              " 247: 4740,\n",
              " 248: 2995,\n",
              " 249: 419,\n",
              " 250: 1306,\n",
              " 251: 5124,\n",
              " 252: 2684,\n",
              " 253: 4166,\n",
              " 254: 4897,\n",
              " 255: 8,\n",
              " 256: 3462,\n",
              " 257: 2197,\n",
              " 258: 2235,\n",
              " 259: 4867,\n",
              " 260: 2675,\n",
              " 261: 2601,\n",
              " 262: 4358,\n",
              " 263: 3753,\n",
              " 264: 2678,\n",
              " 265: 4911,\n",
              " 266: 3619,\n",
              " 267: 4677,\n",
              " 268: 4310,\n",
              " 269: 3448,\n",
              " 270: 2471,\n",
              " 271: 3474,\n",
              " 272: 2835,\n",
              " 273: 5247,\n",
              " 274: 4835,\n",
              " 275: 2472,\n",
              " 276: 2327,\n",
              " 277: 3372,\n",
              " 278: 4805,\n",
              " 279: 624,\n",
              " 280: 2000,\n",
              " 281: 4550,\n",
              " 282: 2095,\n",
              " 283: 4193,\n",
              " 284: 1636,\n",
              " 285: 782,\n",
              " 286: 2330,\n",
              " 287: 4230,\n",
              " 288: 4983,\n",
              " 289: 551,\n",
              " 290: 4296,\n",
              " 291: 4318,\n",
              " 292: 1165,\n",
              " 293: 898,\n",
              " 294: 3996,\n",
              " 295: 5046,\n",
              " 296: 4787,\n",
              " 297: 1010,\n",
              " 298: 5300,\n",
              " 299: 3399,\n",
              " 300: 619,\n",
              " 301: 2938,\n",
              " 302: 4593,\n",
              " 303: 4278,\n",
              " 304: 2651,\n",
              " 305: 1438,\n",
              " 306: 502,\n",
              " 307: 1475,\n",
              " 308: 1760,\n",
              " 309: 3615,\n",
              " 310: 1718,\n",
              " 311: 2986,\n",
              " 312: 3661,\n",
              " 313: 1695,\n",
              " 314: 3594,\n",
              " 315: 4880,\n",
              " 316: 4530,\n",
              " 317: 2973,\n",
              " 318: 3693,\n",
              " 319: 4305,\n",
              " 320: 769,\n",
              " 321: 3180,\n",
              " 322: 1034,\n",
              " 323: 1145,\n",
              " 324: 1478,\n",
              " 325: 1270,\n",
              " 326: 1116,\n",
              " 327: 5235,\n",
              " 328: 2956,\n",
              " 329: 3097,\n",
              " 330: 2502,\n",
              " 331: 3647,\n",
              " 332: 2415,\n",
              " 333: 1527,\n",
              " 334: 2287,\n",
              " 335: 3060,\n",
              " 336: 2086,\n",
              " 337: 1119,\n",
              " 338: 1135,\n",
              " 339: 4952,\n",
              " 340: 2277,\n",
              " 341: 4716,\n",
              " 342: 683,\n",
              " 343: 4049,\n",
              " 344: 1531,\n",
              " 345: 2657,\n",
              " 346: 1168,\n",
              " 347: 2716,\n",
              " 348: 2772,\n",
              " 349: 592,\n",
              " 350: 3716,\n",
              " 351: 3489,\n",
              " 352: 4477,\n",
              " 353: 4632,\n",
              " 354: 2996,\n",
              " 355: 90,\n",
              " 356: 3512,\n",
              " 357: 880,\n",
              " 358: 4692,\n",
              " 359: 4002,\n",
              " 360: 4297,\n",
              " 361: 456,\n",
              " 362: 4076,\n",
              " 363: 1785,\n",
              " 364: 430,\n",
              " 365: 1512,\n",
              " 366: 877,\n",
              " 367: 4827,\n",
              " 368: 3746,\n",
              " 369: 903,\n",
              " 370: 1031,\n",
              " 371: 1417,\n",
              " 372: 3332,\n",
              " 373: 1412,\n",
              " 374: 56,\n",
              " 375: 2639,\n",
              " 376: 3150,\n",
              " 377: 4048,\n",
              " 378: 2969,\n",
              " 379: 2867,\n",
              " 380: 4937,\n",
              " 381: 181,\n",
              " 382: 2989,\n",
              " 383: 1930,\n",
              " 384: 889,\n",
              " 385: 156,\n",
              " 386: 1103,\n",
              " 387: 660,\n",
              " 388: 3338,\n",
              " 389: 4118,\n",
              " 390: 3310,\n",
              " 391: 2108,\n",
              " 392: 1926,\n",
              " 393: 925,\n",
              " 394: 709,\n",
              " 395: 2302,\n",
              " 396: 4504,\n",
              " 397: 1397,\n",
              " 398: 1839,\n",
              " 399: 2702,\n",
              " 400: 3795,\n",
              " 401: 2626,\n",
              " 402: 4664,\n",
              " 403: 1430,\n",
              " 404: 4588,\n",
              " 405: 756,\n",
              " 406: 2780,\n",
              " 407: 2825,\n",
              " 408: 2301,\n",
              " 409: 2114,\n",
              " 410: 3830,\n",
              " 411: 4052,\n",
              " 412: 1714,\n",
              " 413: 4374,\n",
              " 414: 743,\n",
              " 415: 2016,\n",
              " 416: 2134,\n",
              " 417: 4996,\n",
              " 418: 3669,\n",
              " 419: 4893,\n",
              " 420: 4332,\n",
              " 421: 47,\n",
              " 422: 2738,\n",
              " 423: 2162,\n",
              " 424: 4812,\n",
              " 425: 3041,\n",
              " 426: 3418,\n",
              " 427: 3430,\n",
              " 428: 4932,\n",
              " 429: 1141,\n",
              " 430: 4778,\n",
              " 431: 3407,\n",
              " 432: 2014,\n",
              " 433: 3928,\n",
              " 434: 1939,\n",
              " 435: 3845,\n",
              " 436: 2193,\n",
              " 437: 96,\n",
              " 438: 3723,\n",
              " 439: 1112,\n",
              " 440: 1717,\n",
              " 441: 2001,\n",
              " 442: 387,\n",
              " 443: 5284,\n",
              " 444: 398,\n",
              " 445: 4560,\n",
              " 446: 720,\n",
              " 447: 4539,\n",
              " 448: 2721,\n",
              " 449: 4245,\n",
              " 450: 3755,\n",
              " 451: 1092,\n",
              " 452: 3381,\n",
              " 453: 1359,\n",
              " 454: 2023,\n",
              " 455: 5117,\n",
              " 456: 1332,\n",
              " 457: 3473,\n",
              " 458: 612,\n",
              " 459: 4482,\n",
              " 460: 4775,\n",
              " 461: 3602,\n",
              " 462: 2181,\n",
              " 463: 122,\n",
              " 464: 5105,\n",
              " 465: 2880,\n",
              " 466: 4102,\n",
              " 467: 457,\n",
              " 468: 4540,\n",
              " 469: 4768,\n",
              " 470: 1308,\n",
              " 471: 108,\n",
              " 472: 1759,\n",
              " 473: 476,\n",
              " 474: 3979,\n",
              " 475: 3864,\n",
              " 476: 3449,\n",
              " 477: 5316,\n",
              " 478: 5104,\n",
              " 479: 2032,\n",
              " 480: 368,\n",
              " 481: 2711,\n",
              " 482: 130,\n",
              " 483: 5208,\n",
              " 484: 4169,\n",
              " 485: 1000,\n",
              " 486: 151,\n",
              " 487: 1666,\n",
              " 488: 3433,\n",
              " 489: 1483,\n",
              " 490: 3655,\n",
              " 491: 2553,\n",
              " 492: 4488,\n",
              " 493: 2682,\n",
              " 494: 3317,\n",
              " 495: 1859,\n",
              " 496: 2350,\n",
              " 497: 4424,\n",
              " 498: 519,\n",
              " 499: 4098,\n",
              " 500: 234,\n",
              " 501: 2530,\n",
              " 502: 1945,\n",
              " 503: 2895,\n",
              " 504: 1384,\n",
              " 505: 4534,\n",
              " 506: 2126,\n",
              " 507: 2828,\n",
              " 508: 5311,\n",
              " 509: 3855,\n",
              " 510: 1401,\n",
              " 511: 3754,\n",
              " 512: 3389,\n",
              " 513: 2427,\n",
              " 514: 4152,\n",
              " 515: 3394,\n",
              " 516: 3550,\n",
              " 517: 4665,\n",
              " 518: 719,\n",
              " 519: 3167,\n",
              " 520: 621,\n",
              " 521: 1441,\n",
              " 522: 2819,\n",
              " 523: 3793,\n",
              " 524: 2755,\n",
              " 525: 3618,\n",
              " 526: 2729,\n",
              " 527: 4044,\n",
              " 528: 535,\n",
              " 529: 1093,\n",
              " 530: 129,\n",
              " 531: 2640,\n",
              " 532: 2105,\n",
              " 533: 3852,\n",
              " 534: 365,\n",
              " 535: 475,\n",
              " 536: 3367,\n",
              " 537: 1799,\n",
              " 538: 5095,\n",
              " 539: 4984,\n",
              " 540: 433,\n",
              " 541: 451,\n",
              " 542: 416,\n",
              " 543: 5062,\n",
              " 544: 2787,\n",
              " 545: 5132,\n",
              " 546: 2240,\n",
              " 547: 161,\n",
              " 548: 3147,\n",
              " 549: 3136,\n",
              " 550: 4671,\n",
              " 551: 3291,\n",
              " 552: 2887,\n",
              " 553: 812,\n",
              " 554: 361,\n",
              " 555: 5277,\n",
              " 556: 3885,\n",
              " 557: 3707,\n",
              " 558: 890,\n",
              " 559: 2244,\n",
              " 560: 4344,\n",
              " 561: 1982,\n",
              " 562: 4019,\n",
              " 563: 31,\n",
              " 564: 2005,\n",
              " 565: 1414,\n",
              " 566: 651,\n",
              " 567: 1329,\n",
              " 568: 1634,\n",
              " 569: 1174,\n",
              " 570: 4379,\n",
              " 571: 4104,\n",
              " 572: 3264,\n",
              " 573: 418,\n",
              " 574: 5128,\n",
              " 575: 4927,\n",
              " 576: 3540,\n",
              " 577: 4282,\n",
              " 578: 3568,\n",
              " 579: 82,\n",
              " 580: 712,\n",
              " 581: 17,\n",
              " 582: 866,\n",
              " 583: 3119,\n",
              " 584: 4458,\n",
              " 585: 2251,\n",
              " 586: 623,\n",
              " 587: 3410,\n",
              " 588: 5200,\n",
              " 589: 3598,\n",
              " 590: 2766,\n",
              " 591: 2602,\n",
              " 592: 1612,\n",
              " 593: 5331,\n",
              " 594: 2725,\n",
              " 595: 3986,\n",
              " 596: 3393,\n",
              " 597: 4703,\n",
              " 598: 4749,\n",
              " 599: 1694,\n",
              " 600: 5153,\n",
              " 601: 604,\n",
              " 602: 1277,\n",
              " 603: 2432,\n",
              " 604: 4130,\n",
              " 605: 1163,\n",
              " 606: 1498,\n",
              " 607: 4756,\n",
              " 608: 336,\n",
              " 609: 5000,\n",
              " 610: 1879,\n",
              " 611: 1854,\n",
              " 612: 2896,\n",
              " 613: 4300,\n",
              " 614: 4694,\n",
              " 615: 795,\n",
              " 616: 4218,\n",
              " 617: 4315,\n",
              " 618: 3824,\n",
              " 619: 3034,\n",
              " 620: 3893,\n",
              " 621: 3553,\n",
              " 622: 3492,\n",
              " 623: 4179,\n",
              " 624: 3547,\n",
              " 625: 466,\n",
              " 626: 4551,\n",
              " 627: 3674,\n",
              " 628: 1021,\n",
              " 629: 359,\n",
              " 630: 2624,\n",
              " 631: 3327,\n",
              " 632: 2289,\n",
              " 633: 895,\n",
              " 634: 3149,\n",
              " 635: 3827,\n",
              " 636: 5064,\n",
              " 637: 5309,\n",
              " 638: 797,\n",
              " 639: 3190,\n",
              " 640: 4887,\n",
              " 641: 1044,\n",
              " 642: 2811,\n",
              " 643: 1391,\n",
              " 644: 3347,\n",
              " 645: 2713,\n",
              " 646: 3607,\n",
              " 647: 1152,\n",
              " 648: 2451,\n",
              " 649: 557,\n",
              " 650: 2959,\n",
              " 651: 1409,\n",
              " 652: 4640,\n",
              " 653: 792,\n",
              " 654: 5080,\n",
              " 655: 3309,\n",
              " 656: 4657,\n",
              " 657: 4151,\n",
              " 658: 779,\n",
              " 659: 4628,\n",
              " 660: 1230,\n",
              " 661: 3008,\n",
              " 662: 5129,\n",
              " 663: 1402,\n",
              " 664: 3054,\n",
              " 665: 1009,\n",
              " 666: 2972,\n",
              " 667: 2034,\n",
              " 668: 240,\n",
              " 669: 4987,\n",
              " 670: 1563,\n",
              " 671: 4547,\n",
              " 672: 1509,\n",
              " 673: 3535,\n",
              " 674: 73,\n",
              " 675: 4770,\n",
              " 676: 2951,\n",
              " 677: 4941,\n",
              " 678: 4481,\n",
              " 679: 3631,\n",
              " 680: 4521,\n",
              " 681: 1704,\n",
              " 682: 4568,\n",
              " 683: 1431,\n",
              " 684: 3348,\n",
              " 685: 3461,\n",
              " 686: 1186,\n",
              " 687: 3656,\n",
              " 688: 1228,\n",
              " 689: 2976,\n",
              " 690: 2223,\n",
              " 691: 4119,\n",
              " 692: 2098,\n",
              " 693: 2980,\n",
              " 694: 3652,\n",
              " 695: 1170,\n",
              " 696: 106,\n",
              " 697: 1868,\n",
              " 698: 935,\n",
              " 699: 4426,\n",
              " 700: 1973,\n",
              " 701: 100,\n",
              " 702: 4847,\n",
              " 703: 622,\n",
              " 704: 1149,\n",
              " 705: 1570,\n",
              " 706: 2532,\n",
              " 707: 4033,\n",
              " 708: 4683,\n",
              " 709: 3432,\n",
              " 710: 3371,\n",
              " 711: 3913,\n",
              " 712: 4673,\n",
              " 713: 2146,\n",
              " 714: 3002,\n",
              " 715: 585,\n",
              " 716: 4858,\n",
              " 717: 1185,\n",
              " 718: 1534,\n",
              " 719: 1269,\n",
              " 720: 2386,\n",
              " 721: 1495,\n",
              " 722: 2145,\n",
              " 723: 1416,\n",
              " 724: 3483,\n",
              " 725: 2002,\n",
              " 726: 441,\n",
              " 727: 2382,\n",
              " 728: 5227,\n",
              " 729: 102,\n",
              " 730: 2620,\n",
              " 731: 1554,\n",
              " 732: 2726,\n",
              " 733: 4670,\n",
              " 734: 1418,\n",
              " 735: 4739,\n",
              " 736: 2178,\n",
              " 737: 2914,\n",
              " 738: 174,\n",
              " 739: 2341,\n",
              " 740: 5268,\n",
              " 741: 2454,\n",
              " 742: 3531,\n",
              " 743: 910,\n",
              " 744: 3565,\n",
              " 745: 1519,\n",
              " 746: 3294,\n",
              " 747: 3274,\n",
              " 748: 1633,\n",
              " 749: 4000,\n",
              " 750: 272,\n",
              " 751: 4934,\n",
              " 752: 2915,\n",
              " 753: 4163,\n",
              " 754: 4474,\n",
              " 755: 4908,\n",
              " 756: 4574,\n",
              " 757: 1880,\n",
              " 758: 4860,\n",
              " 759: 72,\n",
              " 760: 1089,\n",
              " 761: 828,\n",
              " 762: 4519,\n",
              " 763: 2504,\n",
              " 764: 2605,\n",
              " 765: 5191,\n",
              " 766: 4501,\n",
              " 767: 846,\n",
              " 768: 1427,\n",
              " 769: 1055,\n",
              " 770: 4444,\n",
              " 771: 1946,\n",
              " 772: 452,\n",
              " 773: 3883,\n",
              " 774: 1012,\n",
              " 775: 3255,\n",
              " 776: 4354,\n",
              " 777: 1464,\n",
              " 778: 4377,\n",
              " 779: 1446,\n",
              " 780: 2286,\n",
              " 781: 1766,\n",
              " 782: 4614,\n",
              " 783: 4818,\n",
              " 784: 3597,\n",
              " 785: 5067,\n",
              " 786: 178,\n",
              " 787: 212,\n",
              " 788: 1953,\n",
              " 789: 2573,\n",
              " 790: 404,\n",
              " 791: 2760,\n",
              " 792: 628,\n",
              " 793: 5211,\n",
              " 794: 2732,\n",
              " 795: 1670,\n",
              " 796: 2309,\n",
              " 797: 883,\n",
              " 798: 1087,\n",
              " 799: 4313,\n",
              " 800: 2333,\n",
              " 801: 4850,\n",
              " 802: 3668,\n",
              " 803: 3777,\n",
              " 804: 158,\n",
              " 805: 3752,\n",
              " 806: 3784,\n",
              " 807: 292,\n",
              " 808: 2424,\n",
              " 809: 1662,\n",
              " 810: 1435,\n",
              " 811: 2089,\n",
              " 812: 4915,\n",
              " 813: 3853,\n",
              " 814: 2212,\n",
              " 815: 1779,\n",
              " 816: 3829,\n",
              " 817: 2042,\n",
              " 818: 3733,\n",
              " 819: 5230,\n",
              " 820: 1677,\n",
              " 821: 522,\n",
              " 822: 1783,\n",
              " 823: 4776,\n",
              " 824: 2767,\n",
              " 825: 904,\n",
              " 826: 3329,\n",
              " 827: 1436,\n",
              " 828: 210,\n",
              " 829: 2465,\n",
              " 830: 3705,\n",
              " 831: 3271,\n",
              " 832: 1707,\n",
              " 833: 1463,\n",
              " 834: 531,\n",
              " 835: 3450,\n",
              " 836: 275,\n",
              " 837: 2200,\n",
              " 838: 2242,\n",
              " 839: 5329,\n",
              " 840: 922,\n",
              " 841: 2599,\n",
              " 842: 3224,\n",
              " 843: 5269,\n",
              " 844: 1226,\n",
              " 845: 3069,\n",
              " 846: 2143,\n",
              " 847: 352,\n",
              " 848: 682,\n",
              " 849: 4061,\n",
              " 850: 3917,\n",
              " 851: 3212,\n",
              " 852: 591,\n",
              " 853: 4222,\n",
              " 854: 1032,\n",
              " 855: 3787,\n",
              " 856: 663,\n",
              " 857: 2293,\n",
              " 858: 1144,\n",
              " 859: 5212,\n",
              " 860: 5037,\n",
              " 861: 5207,\n",
              " 862: 870,\n",
              " 863: 5172,\n",
              " 864: 1847,\n",
              " 865: 1877,\n",
              " 866: 1730,\n",
              " 867: 4148,\n",
              " 868: 367,\n",
              " 869: 4734,\n",
              " 870: 2273,\n",
              " 871: 2227,\n",
              " 872: 3153,\n",
              " 873: 1099,\n",
              " 874: 4322,\n",
              " 875: 5084,\n",
              " 876: 969,\n",
              " 877: 1291,\n",
              " 878: 3160,\n",
              " 879: 2270,\n",
              " 880: 1889,\n",
              " 881: 4651,\n",
              " 882: 11,\n",
              " 883: 3359,\n",
              " 884: 354,\n",
              " 885: 2161,\n",
              " 886: 686,\n",
              " 887: 3019,\n",
              " 888: 4678,\n",
              " 889: 1849,\n",
              " 890: 99,\n",
              " 891: 2734,\n",
              " 892: 4123,\n",
              " 893: 3762,\n",
              " 894: 3316,\n",
              " 895: 4699,\n",
              " 896: 940,\n",
              " 897: 1701,\n",
              " 898: 4848,\n",
              " 899: 765,\n",
              " 900: 5197,\n",
              " 901: 3802,\n",
              " 902: 3843,\n",
              " 903: 3258,\n",
              " 904: 5003,\n",
              " 905: 1138,\n",
              " 906: 1160,\n",
              " 907: 2590,\n",
              " 908: 30,\n",
              " 909: 88,\n",
              " 910: 907,\n",
              " 911: 4471,\n",
              " 912: 2429,\n",
              " 913: 5181,\n",
              " 914: 2400,\n",
              " 915: 774,\n",
              " 916: 1422,\n",
              " 917: 638,\n",
              " 918: 3886,\n",
              " 919: 192,\n",
              " 920: 4204,\n",
              " 921: 3137,\n",
              " 922: 3621,\n",
              " 923: 3379,\n",
              " 924: 4478,\n",
              " 925: 4659,\n",
              " 926: 4744,\n",
              " 927: 2603,\n",
              " 928: 2262,\n",
              " 929: 3030,\n",
              " 930: 3616,\n",
              " 931: 3093,\n",
              " 932: 5169,\n",
              " 933: 3541,\n",
              " 934: 5056,\n",
              " 935: 680,\n",
              " 936: 5260,\n",
              " 937: 951,\n",
              " 938: 1914,\n",
              " 939: 3518,\n",
              " 940: 4855,\n",
              " 941: 5152,\n",
              " 942: 1806,\n",
              " 943: 5180,\n",
              " 944: 191,\n",
              " 945: 4272,\n",
              " 946: 3542,\n",
              " 947: 3439,\n",
              " 948: 5306,\n",
              " 949: 5098,\n",
              " 950: 237,\n",
              " 951: 2757,\n",
              " 952: 1221,\n",
              " 953: 1782,\n",
              " 954: 4198,\n",
              " 955: 1999,\n",
              " 956: 681,\n",
              " 957: 3940,\n",
              " 958: 1276,\n",
              " 959: 3575,\n",
              " 960: 4825,\n",
              " 961: 4057,\n",
              " 962: 5253,\n",
              " 963: 3905,\n",
              " 964: 4436,\n",
              " 965: 3980,\n",
              " 966: 654,\n",
              " 967: 4059,\n",
              " 968: 2551,\n",
              " 969: 1582,\n",
              " 970: 933,\n",
              " 971: 4794,\n",
              " 972: 248,\n",
              " 973: 739,\n",
              " 974: 1225,\n",
              " 975: 2982,\n",
              " 976: 2902,\n",
              " 977: 3223,\n",
              " 978: 499,\n",
              " 979: 4173,\n",
              " 980: 864,\n",
              " 981: 2850,\n",
              " 982: 13,\n",
              " 983: 5143,\n",
              " 984: 3080,\n",
              " 985: 3460,\n",
              " 986: 763,\n",
              " 987: 337,\n",
              " 988: 4636,\n",
              " 989: 2514,\n",
              " 990: 3544,\n",
              " 991: 3915,\n",
              " 992: 3809,\n",
              " 993: 3413,\n",
              " 994: 2692,\n",
              " 995: 4704,\n",
              " 996: 5170,\n",
              " 997: 3918,\n",
              " 998: 2940,\n",
              " 999: 5252,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "# Extracting review_ids with indexing\n",
        "review_ids = dataset_split[\"test\"][\"review_id\"]\n",
        "indexed_review_ids = {i: review_id for i, review_id in enumerate(review_ids)}\n",
        "indexed_review_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "GxqPqDA8gm2g"
      },
      "outputs": [],
      "source": [
        "# Creating a pandas dataframe to aggregate and store data\n",
        "# The dataframe contains the review id , the true labels and the predicted ones\n",
        "df_preds = pd.DataFrame({ \"review_id\": review_ids, \"y_test\": y_test, \"y_pred\": y_preds })"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "3WFN6mTUYXQT",
        "outputId": "bf22232e-5f2a-4873-af49-bd9bcf2cfc83"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      review_id  y_test  y_pred\n",
              "0          4384       1       0\n",
              "1          2140       1       0\n",
              "2          3189       1       1\n",
              "3          1543       0       1\n",
              "4          1481       1       1\n",
              "...         ...     ...     ...\n",
              "1062       4232       1       1\n",
              "1063       4184       1       1\n",
              "1064       2013       1       1\n",
              "1065       4212       1       1\n",
              "1066       4442       0       0\n",
              "\n",
              "[1067 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ea0f38d2-4171-45df-bd66-b0608a0a0be2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>y_test</th>\n",
              "      <th>y_pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4384</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2140</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3189</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1543</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1481</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1062</th>\n",
              "      <td>4232</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1063</th>\n",
              "      <td>4184</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1064</th>\n",
              "      <td>2013</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1065</th>\n",
              "      <td>4212</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1066</th>\n",
              "      <td>4442</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1067 rows  3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ea0f38d2-4171-45df-bd66-b0608a0a0be2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ea0f38d2-4171-45df-bd66-b0608a0a0be2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ea0f38d2-4171-45df-bd66-b0608a0a0be2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-acfba087-be9d-4ac9-ac44-f2d4443cf654\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-acfba087-be9d-4ac9-ac44-f2d4443cf654')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-acfba087-be9d-4ac9-ac44-f2d4443cf654 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_59900203-a693-43ad-8871-090604eeeda2\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_preds')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_59900203-a693-43ad-8871-090604eeeda2 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_preds');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_preds",
              "summary": "{\n  \"name\": \"df_preds\",\n  \"rows\": 1067,\n  \"fields\": [\n    {\n      \"column\": \"review_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1556,\n        \"min\": 8,\n        \"max\": 5331,\n        \"num_unique_values\": 1067,\n        \"samples\": [\n          2726,\n          4151,\n          2889\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y_test\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y_pred\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "y63QdBCDgmzK"
      },
      "outputs": [],
      "source": [
        "# Now, we aggregate the predictions by the review\n",
        "# What we want to do is to consider the whole review as a spoiler even if only one chunk is predicted as a spoiler\n",
        "\n",
        "agg_preds = df_preds.groupby(\"review_id\").agg({\"y_test\": \"max\", \"y_pred\": \"max\"}).reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agg_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "nMUeJx6QYenD",
        "outputId": "d59c6206-6f06-48f4-c835-e095ccf8e27f"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      review_id  y_test  y_pred\n",
              "0             8       1       1\n",
              "1             9       1       1\n",
              "2            11       0       0\n",
              "3            13       1       1\n",
              "4            16       1       1\n",
              "...         ...     ...     ...\n",
              "1062       5316       0       1\n",
              "1063       5317       1       0\n",
              "1064       5320       0       1\n",
              "1065       5329       0       0\n",
              "1066       5331       1       0\n",
              "\n",
              "[1067 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eac95018-463b-424e-8f47-4c077351949c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>y_test</th>\n",
              "      <th>y_pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1062</th>\n",
              "      <td>5316</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1063</th>\n",
              "      <td>5317</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1064</th>\n",
              "      <td>5320</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1065</th>\n",
              "      <td>5329</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1066</th>\n",
              "      <td>5331</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1067 rows  3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eac95018-463b-424e-8f47-4c077351949c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-eac95018-463b-424e-8f47-4c077351949c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-eac95018-463b-424e-8f47-4c077351949c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-79a2b024-19ca-4171-babb-9ae65c9ef3c4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-79a2b024-19ca-4171-babb-9ae65c9ef3c4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-79a2b024-19ca-4171-babb-9ae65c9ef3c4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_dff27a2b-7704-4210-9ae6-9649167f0988\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('agg_preds')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_dff27a2b-7704-4210-9ae6-9649167f0988 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('agg_preds');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "agg_preds",
              "summary": "{\n  \"name\": \"agg_preds\",\n  \"rows\": 1067,\n  \"fields\": [\n    {\n      \"column\": \"review_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1556,\n        \"min\": 8,\n        \"max\": 5331,\n        \"num_unique_values\": 1067,\n        \"samples\": [\n          3705,\n          3367,\n          854\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y_test\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y_pred\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21rR_Dk3gmvs",
        "outputId": "8e47264b-db5b-4a23-d2ad-30dfe42f13a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score : 0.7171806167400882\n",
            "Accuracy : 0.6991565135895033\n",
            "Precision: 0.6806020066889632\n",
            "Recall   : 0.7579143389199255\n",
            "ROC AUC  : 0.6987684902146797\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.64      0.68       530\n",
            "           1       0.68      0.76      0.72       537\n",
            "\n",
            "    accuracy                           0.70      1067\n",
            "   macro avg       0.70      0.70      0.70      1067\n",
            "weighted avg       0.70      0.70      0.70      1067\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Evaluating again, with the same metrics this time the whole reviews\n",
        "\n",
        "print(f\"F1 Score : {f1_score(agg_preds['y_test'], agg_preds['y_pred'])}\")\n",
        "print(f\"Accuracy : {accuracy_score(agg_preds['y_test'], agg_preds['y_pred'])}\")\n",
        "print(f\"Precision: {precision_score(agg_preds['y_test'], agg_preds['y_pred'])}\")\n",
        "print(f\"Recall   : {recall_score(agg_preds['y_test'], agg_preds['y_pred'])}\")\n",
        "print(f\"ROC AUC  : {roc_auc_score(agg_preds['y_test'], agg_preds['y_pred'])}\")\n",
        "print(classification_report(agg_preds['y_test'], agg_preds['y_pred']))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TXhhRf_oYjMu"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}